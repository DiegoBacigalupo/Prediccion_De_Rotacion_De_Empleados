{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xwPLWRsLO0H9",
        "UVk0jApPQg-t",
        "2HQZQySuRkPc",
        "WURUyZwiS6g_",
        "BfWC8jqwTf96",
        "-ArvNjcXTr8f",
        "GSMB8p0WUqDH",
        "0p464iTdxXtf",
        "gjhA4p41DJBH",
        "60-U9nzyHnSe",
        "a4qcbeG8ualb",
        "VuyditXXlfXn",
        "RRwz5Rs4eERx",
        "CBNCxMBqiNeR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#🤝 **Predicción de Rotación de Empleados (Employee Churn Prediction)**"
      ],
      "metadata": {
        "id": "aC3cb1OANTME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **🧠Introducción al proyecto**"
      ],
      "metadata": {
        "id": "xwPLWRsLO0H9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el dinámico entorno empresarial actual, la rotación de empleados representa un desafío significativo que impacta directamente en los costos operativos, la productividad y la moral del equipo. Identificar a los empleados en riesgo de abandonar la empresa antes de que lo hagan permite a las organizaciones implementar intervenciones proactivas, reduciendo así las pérdidas asociadas y fomentando un ambiente de trabajo más estable y productivo.\n",
        "\n",
        "Este proyecto aborda la problemática de la rotación mediante el desarrollo de un modelo predictivo de Machine Learning. Utilizando una combinación de datos estructurados (como información demográfica y laboral) y el análisis del feedback de los empleados a través de técnicas de Procesamiento de Lenguaje Natural (NLP), hemos construido una Red Neuronal Multimodal. Este enfoque nos permite no solo predecir qué empleados tienen una alta probabilidad de rotar, sino también entender los factores subyacentes que contribuyen a esta decisión."
      ],
      "metadata": {
        "id": "uo6JeV9JPogu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🎯**Objetivos del Proyecto:**"
      ],
      "metadata": {
        "id": "UVk0jApPQg-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo final es proporcionar a la dirección de Recursos Humanos una herramienta poderosa para optimizar la retención de talento y generar un impacto económico positivo tangible.\n",
        "\n",
        "*   Predecir la Rotación de Empleados\n",
        "*   Integrar Datos Textuales con NLP\n",
        "*   Identificar Factores Clave de Rotación\n",
        "*   Proporcionar Información Accionable a RRHH"
      ],
      "metadata": {
        "id": "KQIDy7PTQsNc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🚀**Motivacion**"
      ],
      "metadata": {
        "id": "2HQZQySuRkPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La motivación principal de este proyecto es dotar a las empresas de una herramienta basada en datos y potenciada por la inteligencia artificial que les permita no solo prever la fuga de talento, sino también comprender sus raíces.\n",
        "Esto se traduce a:\n",
        "*   Prever y comprender la fuga de talento\n",
        "*   Reducir costos\n",
        "*   Mejorar el clima laboral\n",
        "* Optimizar la fuerza laboral\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UbqpMYo6Rzkh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **👥Audiencia**"
      ],
      "metadata": {
        "id": "WURUyZwiS6g_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este proyecto esta dirigido a:\n",
        "\n",
        "\n",
        "*   Líderes de Recursos Humanos (RRHH)\n",
        "*   Gerencia General / Alta Dirección\n",
        "*   Reclutadores / Talent Acquisition Specialists\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nGv4BC81TAEW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **💾Bases de datos**"
      ],
      "metadata": {
        "id": "BfWC8jqwTf96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset?resource=download"
      ],
      "metadata": {
        "id": "bA6_3nokTn_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#📚**Librerias**"
      ],
      "metadata": {
        "id": "-ArvNjcXTr8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Manejo de Datos y Visualización General ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots # Para subplots con Plotly\n",
        "import random # Para la simulación de EmployeeFeedback\n",
        "\n",
        "# --- 2. Preprocesamiento y Modelado de Machine Learning (Scikit-learn) ---\n",
        "from sklearn.model_selection import train_test_split # Para dividir el dataset\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder # Para escalar y codificar variables\n",
        "from sklearn.compose import ColumnTransformer # Para aplicar transformaciones a columnas específicas\n",
        "from sklearn.pipeline import Pipeline # Para encadenar pasos de preprocesamiento y modelo (aunque no lo usamos en la NN multimodal, es útil tenerlo)\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc # Métricas de evaluación\n",
        "\n",
        "# --- 3. Procesamiento de Lenguaje Natural (NLP) ---\n",
        "import nltk\n",
        "import re # Para expresiones regulares en limpieza de texto\n",
        "from nltk.corpus import stopwords # Para remover palabras comunes\n",
        "from nltk.stem import WordNetLemmatizer # Para lematizar palabras (reducir a su forma base)\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer # Para análisis de sentimiento VADER\n",
        "\n",
        "# --- 4. Deep Learning (TensorFlow y Keras) ---\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model # Para construir modelos con múltiples entradas/salidas\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Conv1D, GlobalMaxPooling1D, concatenate, Dropout # Capas de la red neuronal\n",
        "from tensorflow.keras.optimizers import Adam # Optimizador para entrenar la red\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint # Callbacks para el entrenamiento\n",
        "\n",
        "# --- 5. Interactividad (ipywidgets) ---\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, FloatSlider, Layout # Widgets específicos\n",
        "from IPython.display import display, clear_output # Para mostrar widgets y limpiar la salida\n",
        "\n",
        "# --- Configuración Opcional para Visualización ---\n",
        "sns.set_style(\"whitegrid\") # Estilo de Seaborn\n",
        "plt.rcParams['figure.figsize'] = (10, 7) # Tamaño de figura por defecto para Matplotlib\n",
        "\n",
        "print(\"Todas las librerías necesarias han sido importadas exitosamente.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka69sYxHUJ_T",
        "outputId": "d59bccf0-1ef8-445d-aa9e-a2b8f3d217e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Todas las librerías necesarias han sido importadas exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oS_zhxDdDGgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7OvJ9In0xV5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **📊Dataset y adicion de columna de comentarios simulados**"
      ],
      "metadata": {
        "id": "GSMB8p0WUqDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "\n",
        "\n",
        "os.chdir('/content/drive/My Drive/Colab_Notebooks/data_3/PF_Bacigalupo/')\n",
        "\n",
        "# Verificar que estás en el directorio correcto (opcional)\n",
        "print(\"Directorio actual:\", os.getcwd())\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_name = 'HR-Employee.csv'\n",
        "df = pd.read_csv(file_name)\n",
        "\n",
        "# Mostrar las primeras filas para verificar que se cargó correctamente\n",
        "print(\"\\nPrimeras 5 filas del dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Mostrar información general del dataset (tipos de datos, valores nulos)\n",
        "print(\"\\nInformación del dataset:\")\n",
        "df.info()\n",
        "\n",
        "# Mostrar la distribución de la variable objetivo 'Attrition'\n",
        "print(\"\\nDistribución de la rotación (Attrition):\")\n",
        "print(df['Attrition'].value_counts())\n",
        "print(\"\\nPorcentaje de rotación:\")\n",
        "print(df['Attrition'].value_counts(normalize=True) * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "vCmezyAaUz2V",
        "outputId": "56fb6de1-1cd9-41cc-da1c-0c3812eb5a7a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/Colab_Notebooks/data_3/PF_Bacigalupo/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-2835404740.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab_Notebooks/data_3/PF_Bacigalupo/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Verificar que estás en el directorio correcto (opcional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab_Notebooks/data_3/PF_Bacigalupo/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "📜**Agregamos una columna de texto simulado**"
      ],
      "metadata": {
        "id": "0p464iTdxXtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nCreando columna 'EmployeeFeedback' con comentarios simulados en INGLÉS...\")\n",
        "\n",
        "# Frases de feedback negativo para empleados que rotan (en inglés)\n",
        "negative_feedback = [\n",
        "    \"Lack of career growth, felt stagnant.\",\n",
        "    \"Excessive workload, no recognition for overtime.\",\n",
        "    \"Salary was not competitive compared to the market, affecting my motivation.\",\n",
        "    \"Poor management and lack of supervisor support, leading to frustration.\",\n",
        "    \"Work environment became toxic, with little team collaboration.\",\n",
        "    \"No good work-life balance.\",\n",
        "    \"Felt my ideas weren't valued, no room for innovation.\",\n",
        "    \"Lack of adequate training and professional development.\",\n",
        "    \"Issues with leadership, didn't feel heard or understood.\",\n",
        "    \"Too much bureaucracy and inefficient processes.\"\n",
        "]\n",
        "\n",
        "# Frases de feedback positivo/neutral para empleados que no rotan (en inglés)\n",
        "positive_feedback = [\n",
        "    \"Great work environment and a very collaborative team, I feel comfortable.\",\n",
        "    \"Happy with the growth and development opportunities provided.\",\n",
        "    \"Leadership is excellent, I feel supported and motivated by my supervisor.\",\n",
        "    \"I really enjoy my role and the interesting challenges it presents daily.\",\n",
        "    \"Benefits are competitive and there's a good work-life balance.\",\n",
        "    \"I value the autonomy I have in performing my tasks.\",\n",
        "    \"There are always new projects and the company cares about innovation.\",\n",
        "    \"Performance reviews are fair and feedback is constructive.\",\n",
        "    \"I feel part of the company's mission and my work has impact.\",\n",
        "    \"Internal communication is clear and transparent.\"\n",
        "]\n",
        "\n",
        "# Función para asignar feedback basado en la columna 'Attrition'\n",
        "def assign_feedback(attrition_status):\n",
        "    if attrition_status == 'Yes':\n",
        "        return np.random.choice(negative_feedback)\n",
        "    else:\n",
        "        return np.random.choice(positive_feedback)\n",
        "\n",
        "# Aplicar la función para crear la nueva columna 'EmployeeFeedback'\n",
        "df['EmployeeFeedback'] = df['Attrition'].apply(assign_feedback)\n",
        "\n",
        "# Convertir 'Attrition' a numérica (0 o 1) en esta etapa para consistencia\n",
        "# Si ya se hizo, no hay problema, simplemente se reasigna\n",
        "df['Attrition'] = df['Attrition'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "print(\"\\nColumna 'EmployeeFeedback' y 'Attrition' convertida a numérica añadida.\")\n",
        "print(\"Primeras 5 filas con las columnas 'Attrition' y 'EmployeeFeedback':\")\n",
        "print(df[['Attrition', 'EmployeeFeedback']].head())\n",
        "\n",
        "print(\"\\nEjemplos de empleados que rotaron (Attrition=1) y su feedback simulado:\")\n",
        "print(df[df['Attrition'] == 1][['Attrition', 'EmployeeFeedback']].head())\n",
        "\n",
        "print(\"\\nEjemplos de empleados que NO rotaron (Attrition=0) y su feedback simulado:\")\n",
        "print(df[df['Attrition'] == 0][['Attrition', 'EmployeeFeedback']].head())\n",
        "\n",
        "print(\"\\nInformación del dataset actualizada (para confirmar la nueva columna):\")\n",
        "df.info()"
      ],
      "metadata": {
        "id": "etoRdptzBST6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **🔍Analisis y Preparacion del dataset**"
      ],
      "metadata": {
        "id": "gjhA4p41DJBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configuración para gráficos\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (10, 6) # Ajusta el tamaño por defecto de los gráficos\n",
        "plt.rcParams['font.size'] = 12 # Ajusta el tamaño de la fuente"
      ],
      "metadata": {
        "id": "TQeQfO06Da0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vision general del Dataset**"
      ],
      "metadata": {
        "id": "X813vVfcEATn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Información del dataset:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nPrimeras 5 filas del dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nEstadísticas descriptivas de las columnas numéricas:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "5AQLf1zxDvtB",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Análisis de la Variable Objetivo**"
      ],
      "metadata": {
        "id": "AQlJt2teEOml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['Attrition_Label'] = df['Attrition'].map({0: 'No Rotación', 1: 'Sí Rotación'})\n",
        "\n",
        "attrition_counts = df['Attrition_Label'].value_counts().reset_index()\n",
        "attrition_counts.columns = ['Rotación', 'Cantidad de Empleados']\n",
        "\n",
        "fig = px.pie(\n",
        "    attrition_counts,\n",
        "    values='Cantidad de Empleados',\n",
        "    names='Rotación',\n",
        "    title='Distribución de la Rotación de Empleados',\n",
        "    hole=0.3, # Agrega un agujero para un gráfico de rosquilla\n",
        "    color_discrete_sequence=px.colors.sequential.RdBu # Paleta de colores\n",
        ")\n",
        "fig.update_traces(textinfo='percent+label', pull=[0.05, 0]) # Muestra porcentaje y etiqueta, separa ligeramente 'Sí Rotación'\n",
        "fig.show()\n",
        "\n",
        "print(\"\\nPorcentaje de Rotación:\")\n",
        "print(df['Attrition'].value_counts(normalize=True) * 100)"
      ],
      "metadata": {
        "id": "dz2uuKYeEUvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Análisis de Características Numéricas Clave vs. Attrition**"
      ],
      "metadata": {
        "id": "oxfokhQQEfFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_features_to_plot = ['Age', 'MonthlyIncome', 'DistanceFromHome', 'YearsAtCompany', 'HourlyRate', 'TotalWorkingYears']\n",
        "\n",
        "for col in num_features_to_plot:\n",
        "    fig = px.histogram(\n",
        "        df,\n",
        "        x=col,\n",
        "        color='Attrition_Label', # Usa la etiqueta de rotación para diferenciar colores\n",
        "        marginal='box', # Agrega boxplots en los márgenes para ver distribuciones\n",
        "        nbins=50, # Número de \"bins\" para el histograma\n",
        "        title=f'Distribución de {col} por Rotación',\n",
        "        labels={'Attrition_Label': 'Rotación'},\n",
        "        color_discrete_map={'No Rotación': 'blue', 'Sí Rotación': 'red'} # Colores específicos\n",
        "    )\n",
        "    fig.update_layout(bargap=0.1) # Espacio entre barras\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "Xu0LejogEnfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Análisis Interactivo de Características Categóricas Clave vs. Attrition**"
      ],
      "metadata": {
        "id": "JKVGJJOmGTvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_features_to_plot = ['Department', 'JobRole', 'EducationField', 'Gender', 'OverTime', 'BusinessTravel', 'MaritalStatus']\n",
        "\n",
        "for col in cat_features_to_plot:\n",
        "    # Calcular la tasa de rotación por cada categoría\n",
        "    attrition_rate = df.groupby(col)['Attrition'].mean().reset_index()\n",
        "    attrition_rate['Tasa de Rotación (%)'] = attrition_rate['Attrition'] * 100\n",
        "\n",
        "    fig = px.bar(\n",
        "        attrition_rate,\n",
        "        x=col,\n",
        "        y='Tasa de Rotación (%)',\n",
        "        title=f'Tasa de Rotación por {col}',\n",
        "        labels={'Tasa de Rotación (%)': 'Tasa de Rotación (%)'},\n",
        "        color='Tasa de Rotación (%)', # Colorear por la tasa para un gradiente visual\n",
        "        color_continuous_scale=px.colors.sequential.Plasma # Escala de color\n",
        "    )\n",
        "    fig.update_layout(xaxis_tickangle=-45) # Inclinar etiquetas para mejor lectura\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "YpG3H26VGZHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Matriz de Correlación Interactiva (para variables numéricas)**"
      ],
      "metadata": {
        "id": "0hyM1lu8Ge7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcula la correlación solo para columnas numéricas que no sean identificadores o constantes\n",
        "# Y que 'Attrition' sea numérica (0 o 1)\n",
        "df_numeric_for_corr = df.select_dtypes(include=np.number).drop(columns=['EmployeeNumber'], errors='ignore')\n",
        "correlation_matrix = df_numeric_for_corr.corr()\n",
        "\n",
        "fig = px.imshow(\n",
        "    correlation_matrix,\n",
        "    text_auto=True, # Muestra el valor de correlación en las celdas\n",
        "    aspect=\"auto\",\n",
        "    color_continuous_scale=px.colors.sequential.RdBu, # Rojo-Azul para correlaciones positivas/negativas\n",
        "    title='Matriz de Correlación de Variables Numéricas'\n",
        ")\n",
        "fig.update_layout(xaxis_showgrid=False, yaxis_showgrid=False) # Eliminar cuadrícula para mayor claridad\n",
        "fig.show()\n",
        "\n",
        "print(\"\\nCorrelación de características numéricas con Attrition (orden descendente):\")\n",
        "print(correlation_matrix['Attrition'].sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "8iV8_dFrGimX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🗣️**NLP**"
      ],
      "metadata": {
        "id": "60-U9nzyHnSe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LIMPIEZA Y NORMALIZACION BASICA DEL TEXTO**"
      ],
      "metadata": {
        "id": "0gSTELssyLmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "    nltk.download('wordnet', quiet=True)\n",
        "    nltk.download('omw-1.4', quiet=True) # Necesario para WordNetLemmatizer\n",
        "    print(\"Recursos NLTK descargados exitosamente.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al descargar recursos NLTK: {e}.\")\n",
        "    print(\"Por favor, verifica tu conexión a internet o intenta descargar manualmente si persisten los problemas.\")\n",
        "\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Definir la función de limpieza y normalización básica\n",
        "# Usamos text.split() para la tokenización simple por espacios en blanco,\n",
        "# lo cual ayuda a evitar problemas con 'punkt_tab' de NLTK que a veces ocurren en ciertos entornos.\n",
        "def limpieza_y_normalizacion_basica(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = str(text).lower() # Convertir a minúsculas y asegurar que sea string\n",
        "\n",
        "    # 1. Remoción de Puntuación y Caracteres Especiales\n",
        "    # Esto elimina todo lo que no sea una letra, número o espacio.\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # 2. Tokenización (dividir el texto en palabras individuales)\n",
        "    tokens = text.split()\n",
        "\n",
        "    # 3. Remoción de Stopwords (eliminar palabras comunes que no aportan mucho significado)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # 4. Lematización (reducir las palabras a su forma base o raíz gramatical)\n",
        "    # Por ejemplo, \"running\", \"runs\", \"ran\" se convertirían en \"run\".\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "print(\"Inicialización de librerías y función de limpieza básica completada.\")\n",
        "\n",
        "\n",
        "\n",
        "# --- Aplicar la función de limpieza al DataFrame ---\n",
        "# Esto creará una nueva columna 'ProcessedFeedback' con el texto limpio.\n",
        "df['ProcessedFeedback'] = df['EmployeeFeedback'].apply(limpieza_y_normalizacion_basica)\n",
        "\n"
      ],
      "metadata": {
        "id": "jXTNae_xk63M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**COMPARACION TEXTO ORIGINAL VS. PREPROCESADO**"
      ],
      "metadata": {
        "id": "V2H7yF12yryL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Ejemplos de texto original vs. preprocesado (5 muestras aleatorias para comparar):\")\n",
        "print(df[['EmployeeFeedback', 'ProcessedFeedback']].sample(5, random_state=42))\n",
        "\n",
        "print(\"\\nLimpieza y normalización básica del texto completada. Columna 'ProcessedFeedback' creada y lista.\")"
      ],
      "metadata": {
        "id": "jrrM2Pjoypwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 😊**ANÁLISIS DE SENTIMIENTO Y POLARIDAD**"
      ],
      "metadata": {
        "id": "a4qcbeG8ualb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⬇️**Descarga del Léxico VADER e Inicializador de Sentimiento**"
      ],
      "metadata": {
        "id": "MLu7GJTAzbGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "    nltk.download('vader_lexicon', quiet=True)\n",
        "    print(\"Léxico VADER descargado exitosamente.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al descargar léxico VADER: {e}.\")\n",
        "    print(\"Por favor, verifica tu conexión a internet o intenta descargar manualmente.\")\n",
        "\n",
        "# Inicializar el analizador de sentimiento VADER\n",
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "NzoyBZiyueBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "➕**Función para obtener el score compuesto de sentimiento**"
      ],
      "metadata": {
        "id": "SmJNxnvQ01Vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_sentiment_score(text):\n",
        "    if pd.isna(text) or text == \"\":\n",
        "        return 0.0 # Devolver 0 para comentarios vacíos o NaN\n",
        "    score = analyzer.polarity_scores(text)['compound']\n",
        "    return score"
      ],
      "metadata": {
        "id": "FEkrImen0zX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 📊**Aplicación del Análisis de Sentimiento y Creación de la Columna**"
      ],
      "metadata": {
        "id": "wvW6ws0H0_91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Aplicando análisis de sentimiento a 'EmployeeFeedback' y creando 'SentimentScore'...\")\n",
        "\n",
        "# Aplicar la función a la columna original 'EmployeeFeedback'\n",
        "# Para VADER, el feedback original suele ser mejor porque conserva la puntuación y las exclamaciones que VADER sabe interpretar.\n",
        "# Sin embargo, dado que ya lematizamos y limpiamos, usar 'ProcessedFeedback' también es válido\n",
        "# si queremos que el score se base puramente en el contenido léxico.\n",
        "# Por simplicidad y para aprovechar el procesamiento anterior, usaremos 'ProcessedFeedback'.\n",
        "df['SentimentScore'] = df['ProcessedFeedback'].apply(get_sentiment_score)\n",
        "\n",
        "print(\"Columna 'SentimentScore' añadida al DataFrame.\")"
      ],
      "metadata": {
        "id": "kQtkR3yM1CVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "👁️**Visualización de Ejemplos y Estadísticas del Sentimiento**"
      ],
      "metadata": {
        "id": "XM7XcxqS1FWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar ejemplos del feedback original, procesado y su puntuación de sentimiento\n",
        "print(\"\\nEjemplos de comentarios y sus puntuaciones de sentimiento (5 muestras aleatorias):\")\n",
        "print(df[['EmployeeFeedback', 'ProcessedFeedback', 'SentimentScore', 'Attrition']].sample(5, random_state=42))\n",
        "\n",
        "# Ver la distribución del SentimentScore\n",
        "print(\"\\nDistribución del 'SentimentScore':\")\n",
        "print(df['SentimentScore'].describe())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "x-J8v7-V1JbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "📈**Visualización Gráfica de la Distribución del Sentimiento**"
      ],
      "metadata": {
        "id": "xlTcSY1f1Pna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "fig = px.histogram(df, x='SentimentScore', color='Attrition',\n",
        "                   title='Distribución del Score de Sentimiento por Attrition',\n",
        "                   labels={'SentimentScore': 'Puntuación de Sentimiento (VADER Compuesto)', 'Attrition': 'Rotación'},\n",
        "                   nbins=50,\n",
        "                   barmode='overlay',\n",
        "                   opacity=0.7)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "-CUJEzje1Rlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 💪🧠**Preparación para Red Neuronal Convolucional/Recurrente y Consolidación de Datos**"
      ],
      "metadata": {
        "id": "VuyditXXlfXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección , daremos el paso crucial para preparar nuestro texto para la rama de la red neuronal convolucional (o recurrente).\n",
        "* Vectorización de Texto para Keras\n",
        "* Preparación de Características Estructuradas\n",
        "* Definición de Entradas del Modelo (X_structured, tokenized_feedback, y)"
      ],
      "metadata": {
        "id": "-blpwpmBlmoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📝**Preparación del Texto para la Rama de la Red Neuronal (TextVectorization) ----------**"
      ],
      "metadata": {
        "id": "Xl2bHlZ22ibP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Usamos el percentil 95 para capturar la mayoría de los comentarios sin hacer las secuencias excesivamente largas.\n",
        "feedback_lengths = [len(str(x).split()) for x in df['ProcessedFeedback']]\n",
        "max_sequence_length = int(np.percentile(feedback_lengths, 95))\n",
        "if max_sequence_length == 0: # Asegurarse que no sea 0 si todos los comentarios son muy cortos\n",
        "    max_sequence_length = 10 # Valor mínimo razonable si los comentarios son muy breves\n",
        "print(f\"Longitud máxima de secuencia (percentil 95 de tokens): {max_sequence_length}\")\n",
        "\n",
        "\n",
        "# Crear una capa TextVectorization de Keras\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=10000, # Un vocabulario de 10,000 palabras es un buen punto de partida.\n",
        "    output_mode='int',\n",
        "    output_sequence_length=max_sequence_length\n",
        ")\n",
        "\n",
        "# Adaptar la capa al texto de entrenamiento para construir el vocabulario.\n",
        "print(\"Construyendo vocabulario y adaptando la capa TextVectorization a los comentarios procesados...\")\n",
        "text_data_for_vocab = np.array(df['ProcessedFeedback'].tolist()) # Convertir a NumPy array\n",
        "vectorize_layer.adapt(text_data_for_vocab)\n",
        "\n",
        "print(f\"Vocabulario construido. Tamaño del vocabulario: {len(vectorize_layer.get_vocabulary())}\")\n",
        "\n",
        "\n",
        "# Transformar todos los comentarios (limpios) en secuencias numéricas usando la capa adaptada.\n",
        "# Este 'tokenized_feedback' será una de las entradas a nuestra red neuronal híbrida.\n",
        "tokenized_feedback = vectorize_layer(text_data_for_vocab).numpy()\n",
        "print(f\"\\nComentarios transformados a secuencias numéricas (tokenized_feedback). Forma: {tokenized_feedback.shape}\")\n",
        "print(\"Primeras 5 secuencias numéricas de comentarios (primeros 10 tokens de cada una):\")\n",
        "print(tokenized_feedback[:5, :10])\n"
      ],
      "metadata": {
        "id": "rMA5bb1LojR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🛠️**Preparación de Características Estructuradas y Definición de X, y ----------**"
      ],
      "metadata": {
        "id": "v3WFR7fq3MQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Columnas que no deben incluirse en las características estructuradas para el modelo.\n",
        "# Esto incluye las columnas que ya hemos procesado para el texto, o identificadores.\n",
        "cols_to_drop_from_structured = [\n",
        "    'EmployeeCount',\n",
        "    'StandardHours',\n",
        "    'Over18',\n",
        "    'EmployeeNumber',\n",
        "    'EmployeeFeedback', # Texto original (ya manejado por la rama de texto)\n",
        "    'ProcessedFeedback',# Texto limpio (ya convertido a tokenized_feedback)\n",
        "\n",
        "]\n",
        "\n",
        "# Crear el DataFrame para las características estructuradas\n",
        "# Asegurarse de que 'Attrition' (la variable objetivo) se mantenga en este df temporalmente para la separación.\n",
        "df_structured_features = df.drop(columns=cols_to_drop_from_structured, errors='ignore')\n",
        "\n",
        "# Definir la variable objetivo (y)\n",
        "# 'Attrition' ya debería ser 0/1 del paso de preparación del dataset.\n",
        "y = df_structured_features['Attrition']\n",
        "\n",
        "# Crear el conjunto de características estructuradas (X_structured)\n",
        "# Eliminamos 'Attrition' de X_structured ya que es nuestra variable objetivo.\n",
        "X_structured = df_structured_features.drop('Attrition', axis=1)\n",
        "\n",
        "# Identificar las características numéricas y categóricas restantes en X_structured\n",
        "# Estas listas serán usadas por ColumnTransformer de scikit-learn en el siguiente paso.\n",
        "numeric_features = X_structured.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = X_structured.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "print(f\"\\nCaracterísticas numéricas identificadas para la rama estructurada: {numeric_features[:10]}...\") # Muestra solo las primeras 10\n",
        "print(f\"Características categóricas identificadas para la rama estructurada: {categorical_features}\")"
      ],
      "metadata": {
        "id": "lNjkR-XH3KGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "📈**Resumen de los Outputs Clave ----------**"
      ],
      "metadata": {
        "id": "lG5A0R-F3gWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- RESUMEN FINAL DEL PREPROCESAMIENTO DE DATOS PARA MODELO MULTIMODAL ---\")\n",
        "print(f\"Variable objetivo 'y' (forma): {y.shape}\")\n",
        "print(f\"Características estructuradas 'X_structured' (forma): {X_structured.shape}\")\n",
        "print(f\"Características de texto procesadas 'tokenized_feedback' (forma): {tokenized_feedback.shape}\")\n",
        "print(f\"Número de características numéricas para rama estructurada: {len(numeric_features)}\")\n",
        "print(f\"Número de características categóricas para rama estructurada: {len(categorical_features)}\")\n",
        "print(f\"Longitud de secuencia fija para texto: {max_sequence_length}\")\n",
        "print(f\"Tamaño del vocabulario de texto: {len(vectorize_layer.get_vocabulary())}\")\n",
        "\n",
        "print(\"\\nLa preparación avanzada del NLP y la consolidación de datos para el modelo multimodal han sido completadas.\")\n",
        "print(\"Los datos están ahora en el formato correcto para ser alimentados a una red neuronal convolucional/recurrente híbrida.\")"
      ],
      "metadata": {
        "id": "eu8qk86V3fme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#🧠 **Red Neuronal Multimodal**"
      ],
      "metadata": {
        "id": "RRwz5Rs4eERx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuestra Red Neuronal Multimodal combina dos ramas: una CNN procesa el texto del feedback (incluyendo el sentimiento), mientras otra rama maneja los datos estructurados del empleado. Ambas se fusionan para aprender patrones complejos y predecir la rotación de manera más precisa, usando toda la información disponible."
      ],
      "metadata": {
        "id": "MACBGb524NTn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**División de Datos y Preprocesamiento de Características Estructuradas**\n",
        "\n",
        "Aquí realizaremos la división estándar de los datos y aplicaremos escalado y codificación a las características estructuradas, mientras que las secuencias de texto ya están preparadas (tokenized_feedback)"
      ],
      "metadata": {
        "id": "4Z_NE4S7o12X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**División de Datos (Train/Test Split)**"
      ],
      "metadata": {
        "id": "HLH5D885778c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_structured_train, X_structured_test, \\\n",
        "tokenized_feedback_train, tokenized_feedback_test, \\\n",
        "y_train, y_test = train_test_split(\n",
        "    X_structured,\n",
        "    tokenized_feedback,\n",
        "    y,\n",
        "    test_size=0.2,    # 20% para el conjunto de prueba\n",
        "    random_state=42,  # Para reproducibilidad en la división\n",
        "    stratify=y        # Mantiene la proporción de la clase 'Attrition' en ambos conjuntos\n",
        ")\n",
        "\n",
        "print(f\"Forma de X_structured_train: {X_structured_train.shape}\")\n",
        "print(f\"Forma de X_structured_test: {X_structured_test.shape}\")\n",
        "print(f\"Forma de tokenized_feedback_train: {tokenized_feedback_train.shape}\")\n",
        "print(f\"Forma de tokenized_feedback_test: {tokenized_feedback_test.shape}\")\n",
        "print(f\"Forma de y_train: {y_train.shape}\")\n",
        "print(f\"Forma de y_test: {y_test.shape}\")\n",
        "print(\"División de datos completada.\")\n"
      ],
      "metadata": {
        "id": "ZhUbJWfS77OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aplicación de Escalado y Codificación**"
      ],
      "metadata": {
        "id": "44aNdm9j8yS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicamos StandardScaler a las características numéricas y OneHotEncoder a las categóricas.\n",
        "# Las características de texto (tokenized_feedback) ya están en un formato numérico adecuado.\n",
        "print(\"\\nAplicando preprocesamiento (escalado numérico y One-Hot Encoding categórico) a las características estructuradas...\")"
      ],
      "metadata": {
        "id": "iPTur2_-9GNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creación de Transformadores**"
      ],
      "metadata": {
        "id": "69ezBPX69HhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear transformadores\n",
        "numeric_transformer = StandardScaler()\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore')"
      ],
      "metadata": {
        "id": "mZFnWVgk9KOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configuración del ColumnTransformer**"
      ],
      "metadata": {
        "id": "OuERcdhB9MP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el ColumnTransformer\n",
        "# Esto aplicará las transformaciones solo a las columnas relevantes de X_structured.\n",
        "preprocessor_structured = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough' # Mantiene columnas no especificadas si las hubiera\n",
        ")"
      ],
      "metadata": {
        "id": "Y2bKfqYZ9NcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ajuste y Transformación de Datos de Entrenamiento**"
      ],
      "metadata": {
        "id": "FlPFXO-d9QEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar (fit) el preprocesador SOLO con los datos de entrenamiento estructurados\n",
        "X_structured_train_processed = preprocessor_structured.fit_transform(X_structured_train)"
      ],
      "metadata": {
        "id": "nKB6LD3F9SL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformación de Datos de Prueba**"
      ],
      "metadata": {
        "id": "DTWV-QLL9TYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformar (NO ajustar) los datos de prueba estructurados usando el preprocesador ya ajustado\n",
        "X_structured_test_processed = preprocessor_structured.transform(X_structured_test)"
      ],
      "metadata": {
        "id": "7RiPrWzL9bj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confirmación de Dimensiones de los Datos Preprocesados**"
      ],
      "metadata": {
        "id": "MX7YskJ69X3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Forma de X_structured_train_processed después del preprocesamiento: {X_structured_train_processed.shape}\")\n",
        "print(f\"Forma de X_structured_test_processed después del preprocesamiento: {X_structured_test_processed.shape}\")\n",
        "print(\"Preprocesamiento de características estructuradas completado.\")"
      ],
      "metadata": {
        "id": "pMpBRG5m9YfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resumen de Datos Listos para el Modelo\n",
        "Ahora tenemos listos:\n",
        "X_structured_train_processed, X_structured_test_processed (para la rama estructurada)\n",
        " tokenized_feedback_train, tokenized_feedback_test (para la rama de texto)\n",
        "y_train, y_test (las etiquetas)"
      ],
      "metadata": {
        "id": "3vMoPh7K9gFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🏗️**Construcción de la Arquitectura del Modelo Multimodal (CNN/RNN Híbrida)**"
      ],
      "metadata": {
        "id": "oAxh0Sc2pKYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección, definiremos la arquitectura de nuestra red neuronal. Será un modelo multimodal, lo que significa que tendrá dos entradas separadas: una para los datos estructurados y otra para las secuencias de texto. Ambas entradas se procesarán en ramas distintas antes de fusionarse para la predicción final."
      ],
      "metadata": {
        "id": "TmvLqwdtpUGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros para la rama de texto\n",
        "vocab_size = len(vectorize_layer.get_vocabulary())\n",
        "embedding_dim = 128 # Dimensión del espacio de embedding para las palabras\n",
        "filters = 128       # Número de filtros para la capa Conv1D\n",
        "kernel_size = 5     # Tamaño del kernel (ventana) para la capa Conv1D\n",
        "\n",
        "# Parámetros para la rama estructurada\n",
        "structured_input_shape = X_structured_train_processed.shape[1]\n",
        "\n",
        "# Parámetros generales del modelo\n",
        "dense_units = 64    # Unidades en las capas densas ocultas\n",
        "dropout_rate = 0.3  # Tasa de dropout para regularización\n",
        "learning_rate = 0.001 # Tasa de aprendizaje para el optimizador Adam\n",
        "\n",
        "print(f\"\\nParámetros del modelo:\")\n",
        "print(f\"  Tamaño del vocabulario (texto): {vocab_size}\")\n",
        "print(f\"  Dimensión de embedding: {embedding_dim}\")\n",
        "print(f\"  Longitud de secuencia máxima: {max_sequence_length}\")\n",
        "print(f\"  Número de características estructuradas: {structured_input_shape}\")\n"
      ],
      "metadata": {
        "id": "_0L52mbrpNMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--- 1. Rama para Datos de Texto (CNN) ---**"
      ],
      "metadata": {
        "id": "mRKBJ7k1-QFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ---  ---\n",
        "print(\"\\nConstruyendo la rama de la Red Neuronal Convolucional (CNN) para los datos de texto...\")\n",
        "text_input = Input(shape=(max_sequence_length,), name='text_input') # Entrada para las secuencias de texto tokenizadas\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length)(text_input)\n",
        "conv_layer = Conv1D(filters, kernel_size, activation='relu')(embedding_layer)\n",
        "pooling_layer = GlobalMaxPooling1D()(conv_layer) # Reducir la dimensionalidad de la salida de la CNN\n",
        "text_branch_output = Dropout(dropout_rate)(pooling_layer)\n",
        "\n"
      ],
      "metadata": {
        "id": "p8SR9iFC-O7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--- 2. Rama para Datos Estructurados ---**"
      ],
      "metadata": {
        "id": "61a8CdM6-Xj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#\n",
        "print(\"Construyendo la rama para los datos estructurados...\")\n",
        "structured_input = Input(shape=(structured_input_shape,), name='structured_input') # Entrada para los datos estructurados preprocesados\n",
        "structured_dense_layer = Dense(dense_units, activation='relu')(structured_input)\n",
        "structured_branch_output = Dropout(dropout_rate)(structured_dense_layer)\n",
        "\n"
      ],
      "metadata": {
        "id": "dlNjPynY-W3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--- 3. Fusión de las Ramas ---**"
      ],
      "metadata": {
        "id": "G5qG7XLt-gpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#\n",
        "print(\"Fusionando las salidas de ambas ramas...\")\n",
        "# Concatenar las salidas de ambas ramas para combinarlas\n",
        "merged_output = concatenate([text_branch_output, structured_branch_output])\n",
        "\n",
        "# Capas densas después de la fusión\n",
        "combined_dense_1 = Dense(dense_units, activation='relu')(merged_output)\n",
        "combined_dropout_1 = Dropout(dropout_rate)(combined_dense_1)\n",
        "combined_dense_2 = Dense(dense_units // 2, activation='relu')(combined_dropout_1) # Otra capa densa más pequeña\n",
        "combined_dropout_2 = Dropout(dropout_rate)(combined_dense_2)\n"
      ],
      "metadata": {
        "id": "awg1KCye-fzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--- 4. Capa de Salida ---**"
      ],
      "metadata": {
        "id": "HaWrYp16-mYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Para clasificación binaria (Attrition: Sí/No), usamos una capa Dense con 1 unidad y activación 'sigmoid'.\n",
        "output_layer = Dense(1, activation='sigmoid', name='output_layer')(combined_dropout_2)\n"
      ],
      "metadata": {
        "id": "xbtUhvAU-lZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--- 5. Creación y Compilación del Modelo ---**"
      ],
      "metadata": {
        "id": "bN6Llq8--sgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "print(\"Creando y compilando el modelo multimodal...\")\n",
        "model = Model(inputs=[text_input, structured_input], outputs=output_layer)\n",
        "\n",
        "# Usamos Adam como optimizador y binary_crossentropy para problemas de clasificación binaria.\n",
        "# metrics: 'accuracy' para la exactitud, 'AUC' para el área bajo la curva ROC (buena para clases desbalanceadas).\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
        "\n",
        "# Mostrar el resumen del modelo para ver la arquitectura\n",
        "print(\"\\nResumen de la arquitectura del modelo:\")\n",
        "model.summary()\n",
        "\n",
        "print(\"\\nArquitectura del modelo multimodal construida y compilada exitosamente.\")"
      ],
      "metadata": {
        "id": "VsX1Cmjb-r0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚙️**Entrenamiento y Evaluación del Modelo Multimodal**"
      ],
      "metadata": {
        "id": "MJY3wWB4pjTZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- 1. Definición de Callbacks para el Entrenamiento ---"
      ],
      "metadata": {
        "id": "xkJ9nYwX-8iY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nConfigurando callbacks para el entrenamiento (EarlyStopping y ModelCheckpoint)...\")\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_multimodal_model.keras', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "print(\"Callbacks configurados.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Qmof_XQCqGv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- 2. Entrenamiento del Modelo ---"
      ],
      "metadata": {
        "id": "SVj_8nz0_EaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit(\n",
        "    x=[tokenized_feedback_train, X_structured_train_processed],\n",
        "    y=y_train,\n",
        "    epochs=50, # Puedes ajustar el número máximo de épocas\n",
        "    batch_size=32, # Tamaño del batch, puedes experimentar con 16, 32, 64, etc.\n",
        "    validation_data=([tokenized_feedback_test, X_structured_test_processed], y_test),\n",
        "    callbacks=[early_stopping, model_checkpoint],\n",
        "    verbose=1 # Muestra el progreso del entrenamiento\n",
        ")\n",
        "\n",
        "print(\"\\nEntrenamiento del modelo completado.\")\n",
        "print(\"El mejor modelo ha sido guardado como 'best_multimodal_model.keras'.\")\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZcZC-p4A_DQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " --- 3. Evaluación del Modelo en el Conjunto de Prueba ---"
      ],
      "metadata": {
        "id": "FhC_WC87_NY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "best_model = tf.keras.models.load_model('best_multimodal_model.keras')\n",
        "\n",
        "y_pred_proba = best_model.predict([tokenized_feedback_test, X_structured_test_processed]).ravel()\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# --- Métricas de Clasificación ---\n",
        "print(\"\\n--- Métricas de Clasificación ---\")\n",
        "print(\"Reporte de Clasificación:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"AUC-ROC Score: {auc_score:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nMatriz de Confusión:\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "id": "pxwXSlUn_MR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- 4. Visualización Interactiva de Métricas con Plotly Express ---"
      ],
      "metadata": {
        "id": "Hfbrl0lV_TAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4.1. Gráfico de Historial de Entrenamiento (Pérdida y Precisión)\n",
        "print(\"Generando gráficos interactivos de pérdida y precisión del entrenamiento...\")\n",
        "\n",
        "hist_df = pd.DataFrame(history.history)\n",
        "hist_df['epoch'] = hist_df.index + 1\n",
        "\n",
        "fig_history = make_subplots(rows=1, cols=2, subplot_titles=('Pérdida del Modelo', 'Precisión del Modelo'))\n",
        "\n",
        "# Gráfico de Pérdida\n",
        "fig_history.add_trace(go.Scatter(x=hist_df['epoch'], y=hist_df['loss'], mode='lines', name='Pérdida de Entrenamiento'), row=1, col=1)\n",
        "fig_history.add_trace(go.Scatter(x=hist_df['epoch'], y=hist_df['val_loss'], mode='lines', name='Pérdida de Validación'), row=1, col=1)\n",
        "fig_history.update_xaxes(title_text='Época', row=1, col=1)\n",
        "fig_history.update_yaxes(title_text='Pérdida', row=1, col=1)\n",
        "fig_history.update_layout(hovermode=\"x unified\") # Para mejor interactividad\n",
        "\n",
        "# Gráfico de Precisión\n",
        "fig_history.add_trace(go.Scatter(x=hist_df['epoch'], y=hist_df['accuracy'], mode='lines', name='Precisión de Entrenamiento'), row=1, col=2)\n",
        "fig_history.add_trace(go.Scatter(x=hist_df['epoch'], y=hist_df['val_accuracy'], mode='lines', name='Precisión de Validación'), row=1, col=2)\n",
        "fig_history.update_xaxes(title_text='Época', row=1, col=2)\n",
        "fig_history.update_yaxes(title_text='Precisión', row=1, col=2)\n",
        "fig_history.update_layout(title_text=\"Historial de Entrenamiento del Modelo\", height=500, showlegend=True) # showlegend=True en layout principal\n",
        "fig_history.show()\n",
        "\n",
        "\n",
        "# 4.2. Curva ROC Interactiva\n",
        "print(\"Generando curva ROC interactiva...\")\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Crear DataFrame para la curva ROC para Plotly Express\n",
        "roc_df = pd.DataFrame({'FPR': fpr, 'TPR': tpr, 'Threshold': thresholds})\n",
        "\n",
        "fig_roc = px.area(\n",
        "    roc_df,\n",
        "    x=\"FPR\", y=\"TPR\",\n",
        "    title=f'Curva ROC (Área = {roc_auc:.2f})',\n",
        "    labels=dict(x='Tasa de Falsos Positivos (FPR)', y='Tasa de Verdaderos Positivos (TPR)'),\n",
        "    width=700, height=500\n",
        ")\n",
        "fig_roc.add_shape(\n",
        "    type='line', line=dict(dash='dash'),\n",
        "    x0=0, x1=1, y0=0, y1=1\n",
        ")\n",
        "fig_roc.update_traces(hovertemplate=\"FPR: %{x:.2f}<br>TPR: %{y:.2f}<br>Threshold: %{customdata:.2f}\") # Muestra threshold al pasar el mouse\n",
        "fig_roc.data[0].customdata = roc_df['Threshold'] # Asigna los thresholds a customdata\n",
        "fig_roc.show()\n",
        "\n",
        "\n",
        "# 4.3. Matriz de Confusión Interactiva (Heatmap)\n",
        "print(\"Generando matriz de confusión interactiva...\")\n",
        "labels = ['No Attrition', 'Attrition'] # Etiquetas para los ejes\n",
        "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "\n",
        "fig_cm = px.imshow(cm_df,\n",
        "                   text_auto=True,\n",
        "                   labels=dict(x=\"Predicción\", y=\"Valor Real\", color=\"Conteo\"),\n",
        "                   x=labels,\n",
        "                   y=labels,\n",
        "                   color_continuous_scale='Blues',\n",
        "                   title='Matriz de Confusión',\n",
        "                   width=600, height=500)\n",
        "fig_cm.update_xaxes(side=\"top\")\n",
        "fig_cm.show()\n",
        "\n",
        "\n",
        "print(\"\\nEntrenamiento y evaluación del modelo multimodal completados con visualizaciones interactivas.\")\n",
        "print(\"El modelo está listo para su uso o para futuras optimizaciones.\")"
      ],
      "metadata": {
        "id": "nMZOP2bh_SCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusión del Historial de Entrenamiento del Modelo**\n",
        "\n",
        "La gráfica revela una convergencia extremadamente rápida y un excelente rendimiento, con pérdida mínima y precisión casi perfecta en entrenamiento y validación, indicando un modelo robusto y sin sobreajuste."
      ],
      "metadata": {
        "id": "3At0dR3CAnJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 💰**Evaluacion economica**"
      ],
      "metadata": {
        "id": "CBNCxMBqiNeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección, calcularemos el impacto financiero de implementar nuestro modelo de predicción de rotación de empleados. Compararemos el costo anual de rotación sin el modelo versus el costo con el modelo en operación, considerando tanto los ahorros por retención como los costos de las intervenciones."
      ],
      "metadata": {
        "id": "hDVKhbdNrqEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--- 1. Definir Suposiciones Económicas Clave ---**"
      ],
      "metadata": {
        "id": "KpsSVzjGFVWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "y_pred_model = (y_pred_proba > 0.5).astype(int)\n",
        "cm_opt = confusion_matrix(y_test, y_pred_model)\n",
        "\n",
        "\n",
        "\n",
        "average_annual_salary = 60000 # Salario anual promedio de un empleado en USD\n",
        "cost_factor_per_attrition = 1.5 # Costo total de rotación como un múltiplo del salario anual\n",
        "num_employees_company = df.shape[0] # Número total de empleados en la empresa\n",
        "attrition_rate_baseline = y_test.value_counts(normalize=True)[1] if 1 in y_test.value_counts(normalize=True).index else 0 # Tasa de rotación observada\n",
        "\n",
        "cost_per_attrition = average_annual_salary * cost_factor_per_attrition\n",
        "cost_per_false_positive_intervention = 500 # USD por intervención innecesaria\n",
        "retention_success_rate = 0.30 # Tasa de éxito al retener empleados identificados por el modelo\n",
        "\n",
        "print(f\"Salario promedio: ${average_annual_salary:,.2f} | Costo por rotación (factor): {cost_factor_per_attrition}x\")\n",
        "print(f\"Total empleados: {num_employees_company} | Tasa de rotación base: {attrition_rate_baseline:.2%}\")\n",
        "print(f\"Costo por intervención FP: ${cost_per_false_positive_intervention:,.2f} | Éxito de retención: {retention_success_rate:.2%}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "WytWcfbcG7UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--- 2. Calcular el Impacto Económico del Modelo ---**"
      ],
      "metadata": {
        "id": "oUp_q3zUHPiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Desglose de la Matriz de Confusión del conjunto de prueba\n",
        "TN = cm_opt[0, 0]\n",
        "FP = cm_opt[0, 1]\n",
        "FN = cm_opt[1, 0]\n",
        "TP = cm_opt[1, 1]\n",
        "\n",
        "# Calcular tasas de rendimiento del modelo\n",
        "recall_model = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "false_positive_rate = FP / (TN + FP) if (TN + FP) > 0 else 0\n",
        "\n",
        "# Costo Anual de Rotación SIN el Modelo (Escalado a la empresa)\n",
        "actual_churners_company_annual = int(num_employees_company * attrition_rate_baseline)\n",
        "total_cost_without_model = actual_churners_company_annual * cost_per_attrition\n",
        "\n",
        "# Costo Anual de Rotación CON el Modelo (Escalado a la empresa)\n",
        "churners_detected_annual = int(actual_churners_company_annual * recall_model)\n",
        "churners_retained_annual = int(churners_detected_annual * retention_success_rate)\n",
        "\n",
        "unnecessary_interventions_annual = int((num_employees_company - actual_churners_company_annual) * false_positive_rate)\n",
        "cost_of_false_positives = unnecessary_interventions_annual * cost_per_false_positive_intervention\n",
        "\n",
        "# Rotaciones que aún ocurrirán CON el modelo (no detectadas + detectadas pero no retenidas)\n",
        "total_churners_with_model_intervention = (actual_churners_company_annual - churners_retained_annual)\n",
        "cost_from_actual_churn_with_model = total_churners_with_model_intervention * cost_per_attrition\n",
        "\n",
        "total_cost_with_model = cost_from_actual_churn_with_model + cost_of_false_positives\n",
        "\n",
        "# Calcular el ahorro potencial neto anual del modelo\n",
        "net_potential_savings = total_cost_without_model - total_cost_with_model\n"
      ],
      "metadata": {
        "id": "rKEFv_0jHOlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " --- 3. Crear la Tabla Interactiva con Plotly ---"
      ],
      "metadata": {
        "id": "qEJhfXFjHXyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- 3. Resumen Económico del Proyecto ---\")\n",
        "\n",
        "header_values = [\"**Concepto**\", \"**Monto Estimado ($)**\"]\n",
        "cell_values = [\n",
        "    [\"Costo Anual de Rotación (SIN Modelo)\",\n",
        "     \"Costo Anual de Rotación (CON Modelo)\",\n",
        "     \"Ahorro Neto Anual Estimado del Modelo\"],\n",
        "    ['${:,.2f}'.format(total_cost_without_model),\n",
        "     '${:,.2f}'.format(total_cost_with_model),\n",
        "     '${:,.2f}'.format(net_potential_savings)]\n",
        "]\n",
        "\n",
        "cell_colors = [\n",
        "    ['lightgray', 'lightgray', 'lightgray'],\n",
        "    ['#FFCCCC', '#CCFFCC', '#CCCCFF']\n",
        "]\n",
        "\n",
        "fig = go.Figure(data=[go.Table(\n",
        "    header=dict(values=header_values,\n",
        "                fill_color='darkblue',\n",
        "                align='left',\n",
        "                font=dict(color='white', size=14)),\n",
        "    cells=dict(values=cell_values,\n",
        "               fill_color=cell_colors,\n",
        "               align='left',\n",
        "               font=dict(color='black', size=12)))\n",
        "])\n",
        "\n",
        "fig.update_layout(title_text=\"**Resumen Económico del Proyecto de Predicción de Rotación**\", title_x=0.5)\n",
        "fig.show()\n",
        "\n",
        "print(\"\\nEvaluación económica completada y presentada en una tabla interactiva.\")"
      ],
      "metadata": {
        "id": "J1tNukMIHXBw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}