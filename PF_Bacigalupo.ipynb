{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xwPLWRsLO0H9",
        "UVk0jApPQg-t",
        "2HQZQySuRkPc",
        "WURUyZwiS6g_",
        "BfWC8jqwTf96",
        "-ArvNjcXTr8f",
        "GSMB8p0WUqDH",
        "0p464iTdxXtf",
        "gjhA4p41DJBH",
        "60-U9nzyHnSe",
        "a4qcbeG8ualb",
        "VuyditXXlfXn",
        "RRwz5Rs4eERx",
        "CBNCxMBqiNeR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ü§ù **Predicci√≥n de Rotaci√≥n de Empleados (Employee Churn Prediction)**"
      ],
      "metadata": {
        "id": "aC3cb1OANTME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üß†Introducci√≥n al proyecto**"
      ],
      "metadata": {
        "id": "xwPLWRsLO0H9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el din√°mico entorno empresarial actual, la rotaci√≥n de empleados representa un desaf√≠o significativo que impacta directamente en los costos operativos, la productividad y la moral del equipo. Identificar a los empleados en riesgo de abandonar la empresa antes de que lo hagan permite a las organizaciones implementar intervenciones proactivas, reduciendo as√≠ las p√©rdidas asociadas y fomentando un ambiente de trabajo m√°s estable y productivo.\n",
        "\n",
        "Este proyecto aborda la problem√°tica de la rotaci√≥n mediante el desarrollo de un modelo predictivo de Machine Learning. Utilizando una combinaci√≥n de datos estructurados (como informaci√≥n demogr√°fica y laboral) y el an√°lisis del feedback de los empleados a trav√©s de t√©cnicas de Procesamiento de Lenguaje Natural (NLP), hemos construido una Red Neuronal Multimodal. Este enfoque nos permite no solo predecir qu√© empleados tienen una alta probabilidad de rotar, sino tambi√©n entender los factores subyacentes que contribuyen a esta decisi√≥n."
      ],
      "metadata": {
        "id": "uo6JeV9JPogu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üéØ**Objetivos del Proyecto:**"
      ],
      "metadata": {
        "id": "UVk0jApPQg-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo final es proporcionar a la direcci√≥n de Recursos Humanos una herramienta poderosa para optimizar la retenci√≥n de talento y generar un impacto econ√≥mico positivo tangible.\n",
        "\n",
        "*   Predecir la Rotaci√≥n de Empleados\n",
        "*   Integrar Datos Textuales con NLP\n",
        "*   Identificar Factores Clave de Rotaci√≥n\n",
        "*   Proporcionar Informaci√≥n Accionable a RRHH"
      ],
      "metadata": {
        "id": "KQIDy7PTQsNc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ**Motivacion**"
      ],
      "metadata": {
        "id": "2HQZQySuRkPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La motivaci√≥n principal de este proyecto es dotar a las empresas de una herramienta basada en datos y potenciada por la inteligencia artificial que les permita no solo prever la fuga de talento, sino tambi√©n comprender sus ra√≠ces.\n",
        "Esto se traduce a:\n",
        "*   Prever y comprender la fuga de talento\n",
        "*   Reducir costos\n",
        "*   Mejorar el clima laboral\n",
        "* Optimizar la fuerza laboral\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UbqpMYo6Rzkh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üë•Audiencia**"
      ],
      "metadata": {
        "id": "WURUyZwiS6g_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este proyecto esta dirigido a:\n",
        "\n",
        "\n",
        "*   L√≠deres de Recursos Humanos (RRHH)\n",
        "*   Gerencia General / Alta Direcci√≥n\n",
        "*   Reclutadores / Talent Acquisition Specialists\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nGv4BC81TAEW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üíæBases de datos**"
      ],
      "metadata": {
        "id": "BfWC8jqwTf96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset?resource=download"
      ],
      "metadata": {
        "id": "bA6_3nokTn_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìö**Librerias**"
      ],
      "metadata": {
        "id": "-ArvNjcXTr8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Manejo de Datos y Visualizaci√≥n General ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots # Para subplots con Plotly\n",
        "import random # Para la simulaci√≥n de EmployeeFeedback\n",
        "\n",
        "# --- 2. Preprocesamiento y Modelado de Machine Learning (Scikit-learn) ---\n",
        "from sklearn.model_selection import train_test_split # Para dividir el dataset\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder # Para escalar y codificar variables\n",
        "from sklearn.compose import ColumnTransformer # Para aplicar transformaciones a columnas espec√≠ficas\n",
        "from sklearn.pipeline import Pipeline # Para encadenar pasos de preprocesamiento y modelo (aunque no lo usamos en la NN multimodal, es √∫til tenerlo)\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc # M√©tricas de evaluaci√≥n\n",
        "\n",
        "# --- 3. Procesamiento de Lenguaje Natural (NLP) ---\n",
        "import nltk\n",
        "import re # Para expresiones regulares en limpieza de texto\n",
        "from nltk.corpus import stopwords # Para remover palabras comunes\n",
        "from nltk.stem import WordNetLemmatizer # Para lematizar palabras (reducir a su forma base)\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer # Para an√°lisis de sentimiento VADER\n",
        "\n",
        "# --- 4. Deep Learning (TensorFlow y Keras) ---\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model # Para construir modelos con m√∫ltiples entradas/salidas\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Conv1D, GlobalMaxPooling1D, concatenate, Dropout # Capas de la red neuronal\n",
        "from tensorflow.keras.optimizers import Adam # Optimizador para entrenar la red\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint # Callbacks para el entrenamiento\n",
        "\n",
        "# --- 5. Interactividad (ipywidgets) ---\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, FloatSlider, Layout # Widgets espec√≠ficos\n",
        "from IPython.display import display, clear_output # Para mostrar widgets y limpiar la salida\n",
        "\n",
        "# --- Configuraci√≥n Opcional para Visualizaci√≥n ---\n",
        "sns.set_style(\"whitegrid\") # Estilo de Seaborn\n",
        "plt.rcParams['figure.figsize'] = (10, 7) # Tama√±o de figura por defecto para Matplotlib\n",
        "\n",
        "print(\"Todas las librer√≠as necesarias han sido importadas exitosamente.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka69sYxHUJ_T",
        "outputId": "d59bccf0-1ef8-445d-aa9e-a2b8f3d217e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Todas las librer√≠as necesarias han sido importadas exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oS_zhxDdDGgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7OvJ9In0xV5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üìäDataset y adicion de columna de comentarios simulados**"
      ],
      "metadata": {
        "id": "GSMB8p0WUqDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "\n",
        "\n",
        "os.chdir('/content/drive/My Drive/Colab_Notebooks/data_3/PF_Bacigalupo/')\n",
        "\n",
        "# Verificar que est√°s en el directorio correcto (opcional)\n",
        "print(\"Directorio actual:\", os.getcwd())\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_name = 'HR-Employee.csv'\n",
        "df = pd.read_csv(file_name)\n",
        "\n",
        "# Mostrar las primeras filas para verificar que se carg√≥ correctamente\n",
        "print(\"\\nPrimeras 5 filas del dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Mostrar informaci√≥n general del dataset (tipos de datos, valores nulos)\n",
        "print(\"\\nInformaci√≥n del dataset:\")\n",
        "df.info()\n",
        "\n",
        "# Mostrar la distribuci√≥n de la variable objetivo 'Attrition'\n",
        "print(\"\\nDistribuci√≥n de la rotaci√≥n (Attrition):\")\n",
        "print(df['Attrition'].value_counts())\n",
        "print(\"\\nPorcentaje de rotaci√≥n:\")\n",
        "print(df['Attrition'].value_counts(normalize=True) * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "vCmezyAaUz2V",
        "outputId": "56fb6de1-1cd9-41cc-da1c-0c3812eb5a7a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/Colab_Notebooks/data_3/PF_Bacigalupo/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-2835404740.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab_Notebooks/data_3/PF_Bacigalupo/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Verificar que est√°s en el directorio correcto (opcional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab_Notebooks/data_3/PF_Bacigalupo/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìú**Agregamos una columna de texto simulado**"
      ],
      "metadata": {
        "id": "0p464iTdxXtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nCreando columna 'EmployeeFeedback' con comentarios simulados en INGL√âS...\")\n",
        "\n",
        "# Frases de feedback negativo para empleados que rotan (en ingl√©s)\n",
        "negative_feedback = [\n",
        "    \"Lack of career growth, felt stagnant.\",\n",
        "    \"Excessive workload, no recognition for overtime.\",\n",
        "    \"Salary was not competitive compared to the market, affecting my motivation.\",\n",
        "    \"Poor management and lack of supervisor support, leading to frustration.\",\n",
        "    \"Work environment became toxic, with little team collaboration.\",\n",
        "    \"No good work-life balance.\",\n",
        "    \"Felt my ideas weren't valued, no room for innovation.\",\n",
        "    \"Lack of adequate training and professional development.\",\n",
        "    \"Issues with leadership, didn't feel heard or understood.\",\n",
        "    \"Too much bureaucracy and inefficient processes.\"\n",
        "]\n",
        "\n",
        "# Frases de feedback positivo/neutral para empleados que no rotan (en ingl√©s)\n",
        "positive_feedback = [\n",
        "    \"Great work environment and a very collaborative team, I feel comfortable.\",\n",
        "    \"Happy with the growth and development opportunities provided.\",\n",
        "    \"Leadership is excellent, I feel supported and motivated by my supervisor.\",\n",
        "    \"I really enjoy my role and the interesting challenges it presents daily.\",\n",
        "    \"Benefits are competitive and there's a good work-life balance.\",\n",
        "    \"I value the autonomy I have in performing my tasks.\",\n",
        "    \"There are always new projects and the company cares about innovation.\",\n",
        "    \"Performance reviews are fair and feedback is constructive.\",\n",
        "    \"I feel part of the company's mission and my work has impact.\",\n",
        "    \"Internal communication is clear and transparent.\"\n",
        "]\n",
        "\n",
        "# Funci√≥n para asignar feedback basado en la columna 'Attrition'\n",
        "def assign_feedback(attrition_status):\n",
        "    if attrition_status == 'Yes':\n",
        "        return np.random.choice(negative_feedback)\n",
        "    else:\n",
        "        return np.random.choice(positive_feedback)\n",
        "\n",
        "# Aplicar la funci√≥n para crear la nueva columna 'EmployeeFeedback'\n",
        "df['EmployeeFeedback'] = df['Attrition'].apply(assign_feedback)\n",
        "\n",
        "# Convertir 'Attrition' a num√©rica (0 o 1) en esta etapa para consistencia\n",
        "# Si ya se hizo, no hay problema, simplemente se reasigna\n",
        "df['Attrition'] = df['Attrition'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "print(\"\\nColumna 'EmployeeFeedback' y 'Attrition' convertida a num√©rica a√±adida.\")\n",
        "print(\"Primeras 5 filas con las columnas 'Attrition' y 'EmployeeFeedback':\")\n",
        "print(df[['Attrition', 'EmployeeFeedback']].head())\n",
        "\n",
        "print(\"\\nEjemplos de empleados que rotaron (Attrition=1) y su feedback simulado:\")\n",
        "print(df[df['Attrition'] == 1][['Attrition', 'EmployeeFeedback']].head())\n",
        "\n",
        "print(\"\\nEjemplos de empleados que NO rotaron (Attrition=0) y su feedback simulado:\")\n",
        "print(df[df['Attrition'] == 0][['Attrition', 'EmployeeFeedback']].head())\n",
        "\n",
        "print(\"\\nInformaci√≥n del dataset actualizada (para confirmar la nueva columna):\")\n",
        "df.info()"
      ],
      "metadata": {
        "id": "etoRdptzBST6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üîçAnalisis y Preparacion del dataset**"
      ],
      "metadata": {
        "id": "gjhA4p41DJBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configuraci√≥n para gr√°ficos\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (10, 6) # Ajusta el tama√±o por defecto de los gr√°ficos\n",
        "plt.rcParams['font.size'] = 12 # Ajusta el tama√±o de la fuente"
      ],
      "metadata": {
        "id": "TQeQfO06Da0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vision general del Dataset**"
      ],
      "metadata": {
        "id": "X813vVfcEATn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Informaci√≥n del dataset:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nPrimeras 5 filas del dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nEstad√≠sticas descriptivas de las columnas num√©ricas:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "5AQLf1zxDvtB",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**An√°lisis de la Variable Objetivo**"
      ],
      "metadata": {
        "id": "AQlJt2teEOml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['Attrition_Label'] = df['Attrition'].map({0: 'No Rotaci√≥n', 1: 'S√≠ Rotaci√≥n'})\n",
        "\n",
        "attrition_counts = df['Attrition_Label'].value_counts().reset_index()\n",
        "attrition_counts.columns = ['Rotaci√≥n', 'Cantidad de Empleados']\n",
        "\n",
        "fig = px.pie(\n",
        "    attrition_counts,\n",
        "    values='Cantidad de Empleados',\n",
        "    names='Rotaci√≥n',\n",
        "    title='Distribuci√≥n de la Rotaci√≥n de Empleados',\n",
        "    hole=0.3, # Agrega un agujero para un gr√°fico de rosquilla\n",
        "    color_discrete_sequence=px.colors.sequential.RdBu # Paleta de colores\n",
        ")\n",
        "fig.update_traces(textinfo='percent+label', pull=[0.05, 0]) # Muestra porcentaje y etiqueta, separa ligeramente 'S√≠ Rotaci√≥n'\n",
        "fig.show()\n",
        "\n",
        "print(\"\\nPorcentaje de Rotaci√≥n:\")\n",
        "print(df['Attrition'].value_counts(normalize=True) * 100)"
      ],
      "metadata": {
        "id": "dz2uuKYeEUvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**An√°lisis de Caracter√≠sticas Num√©ricas Clave vs. Attrition**"
      ],
      "metadata": {
        "id": "oxfokhQQEfFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_features_to_plot = ['Age', 'MonthlyIncome', 'DistanceFromHome', 'YearsAtCompany', 'HourlyRate', 'TotalWorkingYears']\n",
        "\n",
        "for col in num_features_to_plot:\n",
        "    fig = px.histogram(\n",
        "        df,\n",
        "        x=col,\n",
        "        color='Attrition_Label', # Usa la etiqueta de rotaci√≥n para diferenciar colores\n",
        "        marginal='box', # Agrega boxplots en los m√°rgenes para ver distribuciones\n",
        "        nbins=50, # N√∫mero de \"bins\" para el histograma\n",
        "        title=f'Distribuci√≥n de {col} por Rotaci√≥n',\n",
        "        labels={'Attrition_Label': 'Rotaci√≥n'},\n",
        "        color_discrete_map={'No Rotaci√≥n': 'blue', 'S√≠ Rotaci√≥n': 'red'} # Colores espec√≠ficos\n",
        "    )\n",
        "    fig.update_layout(bargap=0.1) # Espacio entre barras\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "Xu0LejogEnfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**An√°lisis Interactivo de Caracter√≠sticas Categ√≥ricas Clave vs. Attrition**"
      ],
      "metadata": {
        "id": "JKVGJJOmGTvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_features_to_plot = ['Department', 'JobRole', 'EducationField', 'Gender', 'OverTime', 'BusinessTravel', 'MaritalStatus']\n",
        "\n",
        "for col in cat_features_to_plot:\n",
        "    # Calcular la tasa de rotaci√≥n por cada categor√≠a\n",
        "    attrition_rate = df.groupby(col)['Attrition'].mean().reset_index()\n",
        "    attrition_rate['Tasa de Rotaci√≥n (%)'] = attrition_rate['Attrition'] * 100\n",
        "\n",
        "    fig = px.bar(\n",
        "        attrition_rate,\n",
        "        x=col,\n",
        "        y='Tasa de Rotaci√≥n (%)',\n",
        "        title=f'Tasa de Rotaci√≥n por {col}',\n",
        "        labels={'Tasa de Rotaci√≥n (%)': 'Tasa de Rotaci√≥n (%)'},\n",
        "        color='Tasa de Rotaci√≥n (%)', # Colorear por la tasa para un gradiente visual\n",
        "        color_continuous_scale=px.colors.sequential.Plasma # Escala de color\n",
        "    )\n",
        "    fig.update_layout(xaxis_tickangle=-45) # Inclinar etiquetas para mejor lectura\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "YpG3H26VGZHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Matriz de Correlaci√≥n Interactiva (para variables num√©ricas)**"
      ],
      "metadata": {
        "id": "0hyM1lu8Ge7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcula la correlaci√≥n solo para columnas num√©ricas que no sean identificadores o constantes\n",
        "# Y que 'Attrition' sea num√©rica (0 o 1)\n",
        "df_numeric_for_corr = df.select_dtypes(include=np.number).drop(columns=['EmployeeNumber'], errors='ignore')\n",
        "correlation_matrix = df_numeric_for_corr.corr()\n",
        "\n",
        "fig = px.imshow(\n",
        "    correlation_matrix,\n",
        "    text_auto=True, # Muestra el valor de correlaci√≥n en las celdas\n",
        "    aspect=\"auto\",\n",
        "    color_continuous_scale=px.colors.sequential.RdBu, # Rojo-Azul para correlaciones positivas/negativas\n",
        "    title='Matriz de Correlaci√≥n de Variables Num√©ricas'\n",
        ")\n",
        "fig.update_layout(xaxis_showgrid=False, yaxis_showgrid=False) # Eliminar cuadr√≠cula para mayor claridad\n",
        "fig.show()\n",
        "\n",
        "print(\"\\nCorrelaci√≥n de caracter√≠sticas num√©ricas con Attrition (orden descendente):\")\n",
        "print(correlation_matrix['Attrition'].sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "8iV8_dFrGimX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üó£Ô∏è**NLP**"
      ],
      "metadata": {
        "id": "60-U9nzyHnSe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LIMPIEZA Y NORMALIZACION BASICA DEL TEXTO**"
      ],
      "metadata": {
        "id": "0gSTELssyLmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "    nltk.download('wordnet', quiet=True)\n",
        "    nltk.download('omw-1.4', quiet=True) # Necesario para WordNetLemmatizer\n",
        "    print(\"Recursos NLTK descargados exitosamente.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al descargar recursos NLTK: {e}.\")\n",
        "    print(\"Por favor, verifica tu conexi√≥n a internet o intenta descargar manualmente si persisten los problemas.\")\n",
        "\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Definir la funci√≥n de limpieza y normalizaci√≥n b√°sica\n",
        "# Usamos text.split() para la tokenizaci√≥n simple por espacios en blanco,\n",
        "# lo cual ayuda a evitar problemas con 'punkt_tab' de NLTK que a veces ocurren en ciertos entornos.\n",
        "def limpieza_y_normalizacion_basica(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = str(text).lower() # Convertir a min√∫sculas y asegurar que sea string\n",
        "\n",
        "    # 1. Remoci√≥n de Puntuaci√≥n y Caracteres Especiales\n",
        "    # Esto elimina todo lo que no sea una letra, n√∫mero o espacio.\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # 2. Tokenizaci√≥n (dividir el texto en palabras individuales)\n",
        "    tokens = text.split()\n",
        "\n",
        "    # 3. Remoci√≥n de Stopwords (eliminar palabras comunes que no aportan mucho significado)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # 4. Lematizaci√≥n (reducir las palabras a su forma base o ra√≠z gramatical)\n",
        "    # Por ejemplo, \"running\", \"runs\", \"ran\" se convertir√≠an en \"run\".\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "print(\"Inicializaci√≥n de librer√≠as y funci√≥n de limpieza b√°sica completada.\")\n",
        "\n",
        "\n",
        "\n",
        "# --- Aplicar la funci√≥n de limpieza al DataFrame ---\n",
        "# Esto crear√° una nueva columna 'ProcessedFeedback' con el texto limpio.\n",
        "df['ProcessedFeedback'] = df['EmployeeFeedback'].apply(limpieza_y_normalizacion_basica)\n",
        "\n"
      ],
      "metadata": {
        "id": "jXTNae_xk63M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**COMPARACION TEXTO ORIGINAL VS. PREPROCESADO**"
      ],
      "metadata": {
        "id": "V2H7yF12yryL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Ejemplos de texto original vs. preprocesado (5 muestras aleatorias para comparar):\")\n",
        "print(df[['EmployeeFeedback', 'ProcessedFeedback']].sample(5, random_state=42))\n",
        "\n",
        "print(\"\\nLimpieza y normalizaci√≥n b√°sica del texto completada. Columna 'ProcessedFeedback' creada y lista.\")"
      ],
      "metadata": {
        "id": "jrrM2Pjoypwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üòä**AN√ÅLISIS DE SENTIMIENTO Y POLARIDAD**"
      ],
      "metadata": {
        "id": "a4qcbeG8ualb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚¨áÔ∏è**Descarga del L√©xico VADER e Inicializador de Sentimiento**"
      ],
      "metadata": {
        "id": "MLu7GJTAzbGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "    nltk.download('vader_lexicon', quiet=True)\n",
        "    print(\"L√©xico VADER descargado exitosamente.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al descargar l√©xico VADER: {e}.\")\n",
        "    print(\"Por favor, verifica tu conexi√≥n a internet o intenta descargar manualmente.\")\n",
        "\n",
        "# Inicializar el analizador de sentimiento VADER\n",
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "NzoyBZiyueBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ûï**Funci√≥n para obtener el score compuesto de sentimiento**"
      ],
      "metadata": {
        "id": "SmJNxnvQ01Vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_sentiment_score(text):\n",
        "    if pd.isna(text) or text == \"\":\n",
        "        return 0.0 # Devolver 0 para comentarios vac√≠os o NaN\n",
        "    score = analyzer.polarity_scores(text)['compound']\n",
        "    return score"
      ],
      "metadata": {
        "id": "FEkrImen0zX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " üìä**Aplicaci√≥n del An√°lisis de Sentimiento y Creaci√≥n de la Columna**"
      ],
      "metadata": {
        "id": "wvW6ws0H0_91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Aplicando an√°lisis de sentimiento a 'EmployeeFeedback' y creando 'SentimentScore'...\")\n",
        "\n",
        "# Aplicar la funci√≥n a la columna original 'EmployeeFeedback'\n",
        "# Para VADER, el feedback original suele ser mejor porque conserva la puntuaci√≥n y las exclamaciones que VADER sabe interpretar.\n",
        "# Sin embargo, dado que ya lematizamos y limpiamos, usar 'ProcessedFeedback' tambi√©n es v√°lido\n",
        "# si queremos que el score se base puramente en el contenido l√©xico.\n",
        "# Por simplicidad y para aprovechar el procesamiento anterior, usaremos 'ProcessedFeedback'.\n",
        "df['SentimentScore'] = df['ProcessedFeedback'].apply(get_sentiment_score)\n",
        "\n",
        "print(\"Columna 'SentimentScore' a√±adida al DataFrame.\")"
      ],
      "metadata": {
        "id": "kQtkR3yM1CVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëÅÔ∏è**Visualizaci√≥n de Ejemplos y Estad√≠sticas del Sentimiento**"
      ],
      "metadata": {
        "id": "XM7XcxqS1FWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar ejemplos del feedback original, procesado y su puntuaci√≥n de sentimiento\n",
        "print(\"\\nEjemplos de comentarios y sus puntuaciones de sentimiento (5 muestras aleatorias):\")\n",
        "print(df[['EmployeeFeedback', 'ProcessedFeedback', 'SentimentScore', 'Attrition']].sample(5, random_state=42))\n",
        "\n",
        "# Ver la distribuci√≥n del SentimentScore\n",
        "print(\"\\nDistribuci√≥n del 'SentimentScore':\")\n",
        "print(df['SentimentScore'].describe())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "x-J8v7-V1JbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìà**Visualizaci√≥n Gr√°fica de la Distribuci√≥n del Sentimiento**"
      ],
      "metadata": {
        "id": "xlTcSY1f1Pna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "fig = px.histogram(df, x='SentimentScore', color='Attrition',\n",
        "                   title='Distribuci√≥n del Score de Sentimiento por Attrition',\n",
        "                   labels={'SentimentScore': 'Puntuaci√≥n de Sentimiento (VADER Compuesto)', 'Attrition': 'Rotaci√≥n'},\n",
        "                   nbins=50,\n",
        "                   barmode='overlay',\n",
        "                   opacity=0.7)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "-CUJEzje1Rlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üí™üß†**Preparaci√≥n para Red Neuronal Convolucional/Recurrente y Consolidaci√≥n de Datos**"
      ],
      "metadata": {
        "id": "VuyditXXlfXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta secci√≥n , daremos el paso crucial para preparar nuestro texto para la rama de la red neuronal convolucional (o recurrente).\n",
        "* Vectorizaci√≥n de Texto para Keras\n",
        "* Preparaci√≥n de Caracter√≠sticas Estructuradas\n",
        "* Definici√≥n de Entradas del Modelo (X_structured, tokenized_feedback, y)"
      ],
      "metadata": {
        "id": "-blpwpmBlmoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìù**Preparaci√≥n del Texto para la Rama de la Red Neuronal (TextVectorization) ----------**"
      ],
      "metadata": {
        "id": "Xl2bHlZ22ibP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Usamos el percentil 95 para capturar la mayor√≠a de los comentarios sin hacer las secuencias excesivamente largas.\n",
        "feedback_lengths = [len(str(x).split()) for x in df['ProcessedFeedback']]\n",
        "max_sequence_length = int(np.percentile(feedback_lengths, 95))\n",
        "if max_sequence_length == 0: # Asegurarse que no sea 0 si todos los comentarios son muy cortos\n",
        "    max_sequence_length = 10 # Valor m√≠nimo razonable si los comentarios son muy breves\n",
        "print(f\"Longitud m√°xima de secuencia (percentil 95 de tokens): {max_sequence_length}\")\n",
        "\n",
        "\n",
        "# Crear una capa TextVectorization de Keras\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=10000, # Un vocabulario de 10,000 palabras es un buen punto de partida.\n",
        "    output_mode='int',\n",
        "    output_sequence_length=max_sequence_length\n",
        ")\n",
        "\n",
        "# Adaptar la capa al texto de entrenamiento para construir el vocabulario.\n",
        "print(\"Construyendo vocabulario y adaptando la capa TextVectorization a los comentarios procesados...\")\n",
        "text_data_for_vocab = np.array(df['ProcessedFeedback'].tolist()) # Convertir a NumPy array\n",
        "vectorize_layer.adapt(text_data_for_vocab)\n",
        "\n",
        "print(f\"Vocabulario construido. Tama√±o del vocabulario: {len(vectorize_layer.get_vocabulary())}\")\n",
        "\n",
        "\n",
        "# Transformar todos los comentarios (limpios) en secuencias num√©ricas usando la capa adaptada.\n",
        "# Este 'tokenized_feedback' ser√° una de las entradas a nuestra red neuronal h√≠brida.\n",
        "tokenized_feedback = vectorize_layer(text_data_for_vocab).numpy()\n",
        "print(f\"\\nComentarios transformados a secuencias num√©ricas (tokenized_feedback). Forma: {tokenized_feedback.shape}\")\n",
        "print(\"Primeras 5 secuencias num√©ricas de comentarios (primeros 10 tokens de cada una):\")\n",
        "print(tokenized_feedback[:5, :10])\n"
      ],
      "metadata": {
        "id": "rMA5bb1LojR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üõ†Ô∏è**Preparaci√≥n de Caracter√≠sticas Estructuradas y Definici√≥n de X, y ----------**"
      ],
      "metadata": {
        "id": "v3WFR7fq3MQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Columnas que no deben incluirse en las caracter√≠sticas estructuradas para el modelo.\n",
        "# Esto incluye las columnas que ya hemos procesado para el texto, o identificadores.\n",
        "cols_to_drop_from_structured = [\n",
        "    'EmployeeCount',\n",
        "    'StandardHours',\n",
        "    'Over18',\n",
        "    'EmployeeNumber',\n",
        "    'EmployeeFeedback', # Texto original (ya manejado por la rama de texto)\n",
        "    'ProcessedFeedback',# Texto limpio (ya convertido a tokenized_feedback)\n",
        "\n",
        "]\n",
        "\n",
        "# Crear el DataFrame para las caracter√≠sticas estructuradas\n",
        "# Asegurarse de que 'Attrition' (la variable objetivo) se mantenga en este df temporalmente para la separaci√≥n.\n",
        "df_structured_features = df.drop(columns=cols_to_drop_from_structured, errors='ignore')\n",
        "\n",
        "# Definir la variable objetivo (y)\n",
        "# 'Attrition' ya deber√≠a ser 0/1 del paso de preparaci√≥n del dataset.\n",
        "y = df_structured_features['Attrition']\n",
        "\n",
        "# Crear el conjunto de caracter√≠sticas estructuradas (X_structured)\n",
        "# Eliminamos 'Attrition' de X_structured ya que es nuestra variable objetivo.\n",
        "X_structured = df_structured_features.drop('Attrition', axis=1)\n",
        "\n",
        "# Identificar las caracter√≠sticas num√©ricas y categ√≥ricas restantes en X_structured\n",
        "# Estas listas ser√°n usadas por ColumnTransformer de scikit-learn en el siguiente paso.\n",
        "numeric_features = X_structured.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = X_structured.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "print(f\"\\nCaracter√≠sticas num√©ricas identificadas para la rama estructurada: {numeric_features[:10]}...\") # Muestra solo las primeras 10\n",
        "print(f\"Caracter√≠sticas categ√≥ricas identificadas para la rama estructurada: {categorical_features}\")"
      ],
      "metadata": {
        "id": "lNjkR-XH3KGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìà**Resumen de los Outputs Clave ----------**"
      ],
      "metadata": {
        "id": "lG5A0R-F3gWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- RESUMEN FINAL DEL PREPROCESAMIENTO DE DATOS PARA MODELO MULTIMODAL ---\")\n",
        "print(f\"Variable objetivo 'y' (forma): {y.shape}\")\n",
        "print(f\"Caracter√≠sticas estructuradas 'X_structured' (forma): {X_structured.shape}\")\n",
        "print(f\"Caracter√≠sticas de texto procesadas 'tokenized_feedback' (forma): {tokenized_feedback.shape}\")\n",
        "print(f\"N√∫mero de caracter√≠sticas num√©ricas para rama estructurada: {len(numeric_features)}\")\n",
        "print(f\"N√∫mero de caracter√≠sticas categ√≥ricas para rama estructurada: {len(categorical_features)}\")\n",
        "print(f\"Longitud de secuencia fija para texto: {max_sequence_length}\")\n",
        "print(f\"Tama√±o del vocabulario de texto: {len(vectorize_layer.get_vocabulary())}\")\n",
        "\n",
        "print(\"\\nLa preparaci√≥n avanzada del NLP y la consolidaci√≥n de datos para el modelo multimodal han sido completadas.\")\n",
        "print(\"Los datos est√°n ahora en el formato correcto para ser alimentados a una red neuronal convolucional/recurrente h√≠brida.\")"
      ],
      "metadata": {
        "id": "eu8qk86V3fme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üß† **Red Neuronal Multimodal**"
      ],
      "metadata": {
        "id": "RRwz5Rs4eERx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuestra Red Neuronal Multimodal combina dos ramas: una CNN procesa el texto del feedback (incluyendo el sentimiento), mientras otra rama maneja los datos estructurados del empleado. Ambas se fusionan para aprender patrones complejos y predecir la rotaci√≥n de manera m√°s precisa, usando toda la informaci√≥n disponible."
      ],
      "metadata": {
        "id": "MACBGb524NTn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Divisi√≥n de Datos y Preprocesamiento de Caracter√≠sticas Estructuradas**\n",
        "\n",
        "Aqu√≠ realizaremos la divisi√≥n est√°ndar de los datos y aplicaremos escalado y codificaci√≥n a las caracter√≠sticas estructuradas, mientras que las secuencias de texto ya est√°n preparadas (tokenized_feedback)"
      ],
      "metadata": {
        "id": "4Z_NE4S7o12X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Divisi√≥n de Datos (Train/Test Split)**"
      ],
      "metadata": {
        "id": "HLH5D885778c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_structured_train, X_structured_test, \\\n",
        "tokenized_feedback_train, tokenized_feedback_test, \\\n",
        "y_train, y_test = train_test_split(\n",
        "    X_structured,\n",
        "    tokenized_feedback,\n",
        "    y,\n",
        "    test_size=0.2,    # 20% para el conjunto de prueba\n",
        "    random_state=42,  # Para reproducibilidad en la divisi√≥n\n",
        "    stratify=y        # Mantiene la proporci√≥n de la clase 'Attrition' en ambos conjuntos\n",
        ")\n",
        "\n",
        "print(f\"Forma de X_structured_train: {X_structured_train.shape}\")\n",
        "print(f\"Forma de X_structured_test: {X_structured_test.shape}\")\n",
        "print(f\"Forma de tokenized_feedback_train: {tokenized_feedback_train.shape}\")\n",
        "print(f\"Forma de tokenized_feedback_test: {tokenized_feedback_test.shape}\")\n",
        "print(f\"Forma de y_train: {y_train.shape}\")\n",
        "print(f\"Forma de y_test: {y_test.shape}\")\n",
        "print(\"Divisi√≥n de datos completada.\")\n"
      ],
      "metadata": {
        "id": "ZhUbJWfS77OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aplicaci√≥n de Escalado y Codificaci√≥n**"
      ],
      "metadata": {
        "id": "44aNdm9j8yS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicamos StandardScaler a las caracter√≠sticas num√©ricas y OneHotEncoder a las categ√≥ricas.\n",
        "# Las caracter√≠sticas de texto (tokenized_feedback) ya est√°n en un formato num√©rico adecuado.\n",
        "print(\"\\nAplicando preprocesamiento (escalado num√©rico y One-Hot Encoding categ√≥rico) a las caracter√≠sticas estructuradas...\")"
      ],
      "metadata": {
        "id": "iPTur2_-9GNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creaci√≥n de Transformadores**"
      ],
      "metadata": {
        "id": "69ezBPX69HhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear transformadores\n",
        "numeric_transformer = StandardScaler()\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore')"
      ],
      "metadata": {
        "id": "mZFnWVgk9KOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configuraci√≥n del ColumnTransformer**"
      ],
      "metadata": {
        "id": "OuERcdhB9MP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el ColumnTransformer\n",
        "# Esto aplicar√° las transformaciones solo a las columnas relevantes de X_structured.\n",
        "preprocessor_structured = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough' # Mantiene columnas no especificadas si las hubiera\n",
        ")"
      ],
      "metadata": {
        "id": "Y2bKfqYZ9NcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ajuste y Transformaci√≥n de Datos de Entrenamiento**"
      ],
      "metadata": {
        "id": "FlPFXO-d9QEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar (fit) el preprocesador SOLO con los datos de entrenamiento estructurados\n",
        "X_structured_train_processed = preprocessor_structured.fit_transform(X_structured_train)"
      ],
      "metadata": {
        "id": "nKB6LD3F9SL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformaci√≥n de Datos de Prueba**"
      ],
      "metadata": {
        "id": "DTWV-QLL9TYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformar (NO ajustar) los datos de prueba estructurados usando el preprocesador ya ajustado\n",
        "X_structured_test_processed = preprocessor_structured.transform(X_structured_test)"
      ],
      "metadata": {
        "id": "7RiPrWzL9bj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confirmaci√≥n de Dimensiones de los Datos Preprocesados**"
      ],
      "metadata": {
        "id": "MX7YskJ69X3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Forma de X_structured_train_processed despu√©s del preprocesamiento: {X_structured_train_processed.shape}\")\n",
        "print(f\"Forma de X_structured_test_processed despu√©s del preprocesamiento: {X_structured_test_processed.shape}\")\n",
        "print(\"Preprocesamiento de caracter√≠sticas estructuradas completado.\")"
      ],
      "metadata": {
        "id": "pMpBRG5m9YfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resumen de Datos Listos para el Modelo\n",
        "Ahora tenemos listos:\n",
        "X_structured_train_processed, X_structured_test_processed (para la rama estructurada)\n",
        " tokenized_feedback_train, tokenized_feedback_test (para la rama de texto)\n",
        "y_train, y_test (las etiquetas)"
      ],
      "metadata": {
        "id": "3vMoPh7K9gFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üèóÔ∏è**Construcci√≥n de la Arquitectura del Modelo Multimodal (CNN/RNN H√≠brida)**"
      ],
      "metadata": {
        "id": "oAxh0Sc2pKYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta secci√≥n, definiremos la arquitectura de nuestra red neuronal. Ser√° un modelo multimodal, lo que significa que tendr√° dos entradas separadas: una para los datos estructurados y otra para las secuencias de texto. Ambas entradas se procesar√°n en ramas distintas antes de fusionarse para la predicci√≥n final."
      ],
      "metadata": {
        "id": "TmvLqwdtpUGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Par√°metros para la rama de texto\n",
        "vocab_size = len(vectorize_layer.get_vocabulary())\n",
        "embedding_dim = 128 # Dimensi√≥n del espacio de embedding para las palabras\n",
        "filters = 128       # N√∫mero de filtros para la capa Conv1D\n",
        "kernel_size = 5     # Tama√±o del kernel (ventana) para la capa Conv1D\n",
        "\n",
        "# Par√°metros para la rama estructurada\n",
        "structured_input_shape = X_structured_train_processed.shape[1]\n",
        "\n",
        "# Par√°metros generales del modelo\n",
        "dense_units = 64    # Unidades en las capas densas ocultas\n",
        "dropout_rate = 0.3  # Tasa de dropout para regularizaci√≥n\n",
        "learning_rate = 0.001 # Tasa de aprendizaje para el optimizador Adam\n",
        "\n",
        "print(f\"\\nPar√°metros del modelo:\")\n",
        "print(f\"  Tama√±o del vocabulario (texto): {vocab_size}\")\n",
        "print(f\"  Dimensi√≥n de embedding: {embedding_dim}\")\n",
        "print(f\"  Longitud de secuencia m√°xima: {max_sequence_length}\")\n",
        "print(f\"  N√∫mero de caracter√≠sticas estructuradas: {structured_input_shape}\")\n"
      ],
      "metadata": {
        "id": "_0L52mbrpNMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--- 1. Rama para Datos de Texto (CNN) ---**"
      ],
      "metadata": {
        "id": "mRKBJ7k1-QFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ---  ---\n",
        "print(\"\\nConstruyendo la rama de la Red Neuronal Convolucional (CNN) para los datos de texto...\")\n",
        "text_input = Input(shape=(max_sequence_length,), name='text_input') # Entrada para las secuencias de texto tokenizadas\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length)(text_input)\n",
        "conv_layer = Conv1D(filters, kernel_size, activation='relu')(embedding_layer)\n",
        "pooling_layer = GlobalMaxPooling1D()(conv_layer) # Reducir la dimensionalidad de la salida de la CNN\n",
        "text_branch_output = Dropout(dropout_rate)(pooling_layer)\n",
        "\n"
      ],
      "metadata": {
        "id": "p8SR9iFC-O7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--- 2. Rama para Datos Estructurados ---**"
      ],
      "metadata": {
        "id": "61a8CdM6-Xj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#\n",
        "print(\"Construyendo la rama para los datos estructurados...\")\n",
        "structured_input = Input(shape=(structured_input_shape,), name='structured_input') # Entrada para los datos estructurados preprocesados\n",
        "structured_dense_layer = Dense(dense_units, activation='relu')(structured_input)\n",
        "structured_branch_output = Dropout(dropout_rate)(structured_dense_layer)\n",
        "\n"
      ],
      "metadata": {
        "id": "dlNjPynY-W3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--- 3. Fusi√≥n de las Ramas ---**"
      ],
      "metadata": {
        "id": "G5qG7XLt-gpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#\n",
        "print(\"Fusionando las salidas de ambas ramas...\")\n",
        "# Concatenar las salidas de ambas ramas para combinarlas\n",
        "merged_output = concatenate([text_branch_output, structured_branch_output])\n",
        "\n",
        "# Capas densas despu√©s de la fusi√≥n\n",
        "combined_dense_1 = Dense(dense_units, activation='relu')(merged_output)\n",
        "combined_dropout_1 = Dropout(dropout_rate)(combined_dense_1)\n",
        "combined_dense_2 = Dense(dense_units // 2, activation='relu')(combined_dropout_1) # Otra capa densa m√°s peque√±a\n",
        "combined_dropout_2 = Dropout(dropout_rate)(combined_dense_2)\n"
      ],
      "metadata": {
        "id": "awg1KCye-fzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--- 4. Capa de Salida ---**"
      ],
      "metadata": {
        "id": "HaWrYp16-mYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Para clasificaci√≥n binaria (Attrition: S√≠/No), usamos una capa Dense con 1 unidad y activaci√≥n 'sigmoid'.\n",
        "output_layer = Dense(1, activation='sigmoid', name='output_layer')(combined_dropout_2)\n"
      ],
      "metadata": {
        "id": "xbtUhvAU-lZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--- 5. Creaci√≥n y Compilaci√≥n del Modelo ---**"
      ],
      "metadata": {
        "id": "bN6Llq8--sgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "print(\"Creando y compilando el modelo multimodal...\")\n",
        "model = Model(inputs=[text_input, structured_input], outputs=output_layer)\n",
        "\n",
        "# Usamos Adam como optimizador y binary_crossentropy para problemas de clasificaci√≥n binaria.\n",
        "# metrics: 'accuracy' para la exactitud, 'AUC' para el √°rea bajo la curva ROC (buena para clases desbalanceadas).\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
        "\n",
        "# Mostrar el resumen del modelo para ver la arquitectura\n",
        "print(\"\\nResumen de la arquitectura del modelo:\")\n",
        "model.summary()\n",
        "\n",
        "print(\"\\nArquitectura del modelo multimodal construida y compilada exitosamente.\")"
      ],
      "metadata": {
        "id": "VsX1Cmjb-r0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚öôÔ∏è**Entrenamiento y Evaluaci√≥n del Modelo Multimodal**"
      ],
      "metadata": {
        "id": "MJY3wWB4pjTZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- 1. Definici√≥n de Callbacks para el Entrenamiento ---"
      ],
      "metadata": {
        "id": "xkJ9nYwX-8iY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nConfigurando callbacks para el entrenamiento (EarlyStopping y ModelCheckpoint)...\")\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_multimodal_model.keras', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "print(\"Callbacks configurados.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Qmof_XQCqGv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- 2. Entrenamiento del Modelo ---"
      ],
      "metadata": {
        "id": "SVj_8nz0_EaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit(\n",
        "    x=[tokenized_feedback_train, X_structured_train_processed],\n",
        "    y=y_train,\n",
        "    epochs=50, # Puedes ajustar el n√∫mero m√°ximo de √©pocas\n",
        "    batch_size=32, # Tama√±o del batch, puedes experimentar con 16, 32, 64, etc.\n",
        "    validation_data=([tokenized_feedback_test, X_structured_test_processed], y_test),\n",
        "    callbacks=[early_stopping, model_checkpoint],\n",
        "    verbose=1 # Muestra el progreso del entrenamiento\n",
        ")\n",
        "\n",
        "print(\"\\nEntrenamiento del modelo completado.\")\n",
        "print(\"El mejor modelo ha sido guardado como 'best_multimodal_model.keras'.\")\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZcZC-p4A_DQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " --- 3. Evaluaci√≥n del Modelo en el Conjunto de Prueba ---"
      ],
      "metadata": {
        "id": "FhC_WC87_NY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "best_model = tf.keras.models.load_model('best_multimodal_model.keras')\n",
        "\n",
        "y_pred_proba = best_model.predict([tokenized_feedback_test, X_structured_test_processed]).ravel()\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# --- M√©tricas de Clasificaci√≥n ---\n",
        "print(\"\\n--- M√©tricas de Clasificaci√≥n ---\")\n",
        "print(\"Reporte de Clasificaci√≥n:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"AUC-ROC Score: {auc_score:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nMatriz de Confusi√≥n:\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "id": "pxwXSlUn_MR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- 4. Visualizaci√≥n Interactiva de M√©tricas con Plotly Express ---"
      ],
      "metadata": {
        "id": "Hfbrl0lV_TAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4.1. Gr√°fico de Historial de Entrenamiento (P√©rdida y Precisi√≥n)\n",
        "print(\"Generando gr√°ficos interactivos de p√©rdida y precisi√≥n del entrenamiento...\")\n",
        "\n",
        "hist_df = pd.DataFrame(history.history)\n",
        "hist_df['epoch'] = hist_df.index + 1\n",
        "\n",
        "fig_history = make_subplots(rows=1, cols=2, subplot_titles=('P√©rdida del Modelo', 'Precisi√≥n del Modelo'))\n",
        "\n",
        "# Gr√°fico de P√©rdida\n",
        "fig_history.add_trace(go.Scatter(x=hist_df['epoch'], y=hist_df['loss'], mode='lines', name='P√©rdida de Entrenamiento'), row=1, col=1)\n",
        "fig_history.add_trace(go.Scatter(x=hist_df['epoch'], y=hist_df['val_loss'], mode='lines', name='P√©rdida de Validaci√≥n'), row=1, col=1)\n",
        "fig_history.update_xaxes(title_text='√âpoca', row=1, col=1)\n",
        "fig_history.update_yaxes(title_text='P√©rdida', row=1, col=1)\n",
        "fig_history.update_layout(hovermode=\"x unified\") # Para mejor interactividad\n",
        "\n",
        "# Gr√°fico de Precisi√≥n\n",
        "fig_history.add_trace(go.Scatter(x=hist_df['epoch'], y=hist_df['accuracy'], mode='lines', name='Precisi√≥n de Entrenamiento'), row=1, col=2)\n",
        "fig_history.add_trace(go.Scatter(x=hist_df['epoch'], y=hist_df['val_accuracy'], mode='lines', name='Precisi√≥n de Validaci√≥n'), row=1, col=2)\n",
        "fig_history.update_xaxes(title_text='√âpoca', row=1, col=2)\n",
        "fig_history.update_yaxes(title_text='Precisi√≥n', row=1, col=2)\n",
        "fig_history.update_layout(title_text=\"Historial de Entrenamiento del Modelo\", height=500, showlegend=True) # showlegend=True en layout principal\n",
        "fig_history.show()\n",
        "\n",
        "\n",
        "# 4.2. Curva ROC Interactiva\n",
        "print(\"Generando curva ROC interactiva...\")\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Crear DataFrame para la curva ROC para Plotly Express\n",
        "roc_df = pd.DataFrame({'FPR': fpr, 'TPR': tpr, 'Threshold': thresholds})\n",
        "\n",
        "fig_roc = px.area(\n",
        "    roc_df,\n",
        "    x=\"FPR\", y=\"TPR\",\n",
        "    title=f'Curva ROC (√Årea = {roc_auc:.2f})',\n",
        "    labels=dict(x='Tasa de Falsos Positivos (FPR)', y='Tasa de Verdaderos Positivos (TPR)'),\n",
        "    width=700, height=500\n",
        ")\n",
        "fig_roc.add_shape(\n",
        "    type='line', line=dict(dash='dash'),\n",
        "    x0=0, x1=1, y0=0, y1=1\n",
        ")\n",
        "fig_roc.update_traces(hovertemplate=\"FPR: %{x:.2f}<br>TPR: %{y:.2f}<br>Threshold: %{customdata:.2f}\") # Muestra threshold al pasar el mouse\n",
        "fig_roc.data[0].customdata = roc_df['Threshold'] # Asigna los thresholds a customdata\n",
        "fig_roc.show()\n",
        "\n",
        "\n",
        "# 4.3. Matriz de Confusi√≥n Interactiva (Heatmap)\n",
        "print(\"Generando matriz de confusi√≥n interactiva...\")\n",
        "labels = ['No Attrition', 'Attrition'] # Etiquetas para los ejes\n",
        "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "\n",
        "fig_cm = px.imshow(cm_df,\n",
        "                   text_auto=True,\n",
        "                   labels=dict(x=\"Predicci√≥n\", y=\"Valor Real\", color=\"Conteo\"),\n",
        "                   x=labels,\n",
        "                   y=labels,\n",
        "                   color_continuous_scale='Blues',\n",
        "                   title='Matriz de Confusi√≥n',\n",
        "                   width=600, height=500)\n",
        "fig_cm.update_xaxes(side=\"top\")\n",
        "fig_cm.show()\n",
        "\n",
        "\n",
        "print(\"\\nEntrenamiento y evaluaci√≥n del modelo multimodal completados con visualizaciones interactivas.\")\n",
        "print(\"El modelo est√° listo para su uso o para futuras optimizaciones.\")"
      ],
      "metadata": {
        "id": "nMZOP2bh_SCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusi√≥n del Historial de Entrenamiento del Modelo**\n",
        "\n",
        "La gr√°fica revela una convergencia extremadamente r√°pida y un excelente rendimiento, con p√©rdida m√≠nima y precisi√≥n casi perfecta en entrenamiento y validaci√≥n, indicando un modelo robusto y sin sobreajuste."
      ],
      "metadata": {
        "id": "3At0dR3CAnJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üí∞**Evaluacion economica**"
      ],
      "metadata": {
        "id": "CBNCxMBqiNeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta secci√≥n, calcularemos el impacto financiero de implementar nuestro modelo de predicci√≥n de rotaci√≥n de empleados. Compararemos el costo anual de rotaci√≥n sin el modelo versus el costo con el modelo en operaci√≥n, considerando tanto los ahorros por retenci√≥n como los costos de las intervenciones."
      ],
      "metadata": {
        "id": "hDVKhbdNrqEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--- 1. Definir Suposiciones Econ√≥micas Clave ---**"
      ],
      "metadata": {
        "id": "KpsSVzjGFVWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "y_pred_model = (y_pred_proba > 0.5).astype(int)\n",
        "cm_opt = confusion_matrix(y_test, y_pred_model)\n",
        "\n",
        "\n",
        "\n",
        "average_annual_salary = 60000 # Salario anual promedio de un empleado en USD\n",
        "cost_factor_per_attrition = 1.5 # Costo total de rotaci√≥n como un m√∫ltiplo del salario anual\n",
        "num_employees_company = df.shape[0] # N√∫mero total de empleados en la empresa\n",
        "attrition_rate_baseline = y_test.value_counts(normalize=True)[1] if 1 in y_test.value_counts(normalize=True).index else 0 # Tasa de rotaci√≥n observada\n",
        "\n",
        "cost_per_attrition = average_annual_salary * cost_factor_per_attrition\n",
        "cost_per_false_positive_intervention = 500 # USD por intervenci√≥n innecesaria\n",
        "retention_success_rate = 0.30 # Tasa de √©xito al retener empleados identificados por el modelo\n",
        "\n",
        "print(f\"Salario promedio: ${average_annual_salary:,.2f} | Costo por rotaci√≥n (factor): {cost_factor_per_attrition}x\")\n",
        "print(f\"Total empleados: {num_employees_company} | Tasa de rotaci√≥n base: {attrition_rate_baseline:.2%}\")\n",
        "print(f\"Costo por intervenci√≥n FP: ${cost_per_false_positive_intervention:,.2f} | √âxito de retenci√≥n: {retention_success_rate:.2%}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "WytWcfbcG7UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**--- 2. Calcular el Impacto Econ√≥mico del Modelo ---**"
      ],
      "metadata": {
        "id": "oUp_q3zUHPiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Desglose de la Matriz de Confusi√≥n del conjunto de prueba\n",
        "TN = cm_opt[0, 0]\n",
        "FP = cm_opt[0, 1]\n",
        "FN = cm_opt[1, 0]\n",
        "TP = cm_opt[1, 1]\n",
        "\n",
        "# Calcular tasas de rendimiento del modelo\n",
        "recall_model = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "false_positive_rate = FP / (TN + FP) if (TN + FP) > 0 else 0\n",
        "\n",
        "# Costo Anual de Rotaci√≥n SIN el Modelo (Escalado a la empresa)\n",
        "actual_churners_company_annual = int(num_employees_company * attrition_rate_baseline)\n",
        "total_cost_without_model = actual_churners_company_annual * cost_per_attrition\n",
        "\n",
        "# Costo Anual de Rotaci√≥n CON el Modelo (Escalado a la empresa)\n",
        "churners_detected_annual = int(actual_churners_company_annual * recall_model)\n",
        "churners_retained_annual = int(churners_detected_annual * retention_success_rate)\n",
        "\n",
        "unnecessary_interventions_annual = int((num_employees_company - actual_churners_company_annual) * false_positive_rate)\n",
        "cost_of_false_positives = unnecessary_interventions_annual * cost_per_false_positive_intervention\n",
        "\n",
        "# Rotaciones que a√∫n ocurrir√°n CON el modelo (no detectadas + detectadas pero no retenidas)\n",
        "total_churners_with_model_intervention = (actual_churners_company_annual - churners_retained_annual)\n",
        "cost_from_actual_churn_with_model = total_churners_with_model_intervention * cost_per_attrition\n",
        "\n",
        "total_cost_with_model = cost_from_actual_churn_with_model + cost_of_false_positives\n",
        "\n",
        "# Calcular el ahorro potencial neto anual del modelo\n",
        "net_potential_savings = total_cost_without_model - total_cost_with_model\n"
      ],
      "metadata": {
        "id": "rKEFv_0jHOlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " --- 3. Crear la Tabla Interactiva con Plotly ---"
      ],
      "metadata": {
        "id": "qEJhfXFjHXyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- 3. Resumen Econ√≥mico del Proyecto ---\")\n",
        "\n",
        "header_values = [\"**Concepto**\", \"**Monto Estimado ($)**\"]\n",
        "cell_values = [\n",
        "    [\"Costo Anual de Rotaci√≥n (SIN Modelo)\",\n",
        "     \"Costo Anual de Rotaci√≥n (CON Modelo)\",\n",
        "     \"Ahorro Neto Anual Estimado del Modelo\"],\n",
        "    ['${:,.2f}'.format(total_cost_without_model),\n",
        "     '${:,.2f}'.format(total_cost_with_model),\n",
        "     '${:,.2f}'.format(net_potential_savings)]\n",
        "]\n",
        "\n",
        "cell_colors = [\n",
        "    ['lightgray', 'lightgray', 'lightgray'],\n",
        "    ['#FFCCCC', '#CCFFCC', '#CCCCFF']\n",
        "]\n",
        "\n",
        "fig = go.Figure(data=[go.Table(\n",
        "    header=dict(values=header_values,\n",
        "                fill_color='darkblue',\n",
        "                align='left',\n",
        "                font=dict(color='white', size=14)),\n",
        "    cells=dict(values=cell_values,\n",
        "               fill_color=cell_colors,\n",
        "               align='left',\n",
        "               font=dict(color='black', size=12)))\n",
        "])\n",
        "\n",
        "fig.update_layout(title_text=\"**Resumen Econ√≥mico del Proyecto de Predicci√≥n de Rotaci√≥n**\", title_x=0.5)\n",
        "fig.show()\n",
        "\n",
        "print(\"\\nEvaluaci√≥n econ√≥mica completada y presentada en una tabla interactiva.\")"
      ],
      "metadata": {
        "id": "J1tNukMIHXBw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}